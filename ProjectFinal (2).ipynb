{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch.nn.functional as F\n",
    "torch.set_printoptions(linewidth=120)\n",
    "\n",
    "import pickle as serializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function seperates the different commands in 4 different dictionaries\n",
    "# DataDict0 is for command0 'continue'\n",
    "# DataDict1 is for command1 'left' .usw\n",
    "\n",
    "with open('dataset.txt', 'rb') as f:\n",
    "    dataset = serializer.load(f)\n",
    "    \n",
    "DataDictAll = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "DataDict0 = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "DataDict1 = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "DataDict2 = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "DataDict3 = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "\n",
    "keys = dataset.keys()\n",
    "for key in keys:\n",
    "    for label in dataset[key]:\n",
    "        # print(DataDict0)\n",
    "        # Here we code the direction.\n",
    "        # DataDict[\"image\"].append(label[0])\n",
    "        if label[3] == 'left':\n",
    "            label[3] = 0\n",
    "        if label[3] == 'right':\n",
    "            label[3] = 2\n",
    "        if label[3] == 'forward':\n",
    "            label[3] = 1\n",
    "        if key == 'left':\n",
    "            key = 1\n",
    "            '''\n",
    "            label.append(key)\n",
    "            DataDict1[\"image\"].append(label[0])\n",
    "            DataDict1[\"steer\"].append(label[1])\n",
    "            DataDict1[\"throttle\"].append(label[2])\n",
    "            DataDict1[\"direction\"].append(label[3])\n",
    "            DataDict1[\"command\"].append(label[4])\n",
    "            '''\n",
    "        if key == 'right':\n",
    "            key = 3\n",
    "            '''\n",
    "            label.append(key)\n",
    "            DataDict3[\"image\"].append(label[0])\n",
    "            DataDict3[\"steer\"].append(label[1])\n",
    "            DataDict3[\"throttle\"].append(label[2])\n",
    "            DataDict3[\"direction\"].append(label[3])\n",
    "            DataDict3[\"command\"].append(label[4])\n",
    "            '''\n",
    "        if key == 'forward':\n",
    "            key = 2\n",
    "            '''\n",
    "            label.append(key)\n",
    "            DataDict2[\"image\"].append(label[0])\n",
    "            DataDict2[\"steer\"].append(label[1])\n",
    "            DataDict2[\"throttle\"].append(label[2])\n",
    "            DataDict2[\"direction\"].append(label[3])\n",
    "            DataDict2[\"command\"].append(label[4])\n",
    "            '''\n",
    "        if key == 'continue':\n",
    "            key = 0\n",
    "            '''\n",
    "            label.append(key)\n",
    "            DataDict0[\"image\"].append(label[0])\n",
    "            DataDict0[\"steer\"].append(label[1])\n",
    "            DataDict0[\"throttle\"].append(label[2])\n",
    "            DataDict0[\"direction\"].append(label[3])\n",
    "            DataDict0[\"command\"].append(label[4])\n",
    "            '''\n",
    "        gut = 'Bilder/'+ label[0]\n",
    "        if os.path.exists(gut):\n",
    "            if key == 1:  # left\n",
    "                label.append(key)\n",
    "                DataDict1[\"image\"].append(label[0])\n",
    "                DataDict1[\"steer\"].append(label[1])\n",
    "                DataDict1[\"throttle\"].append(label[2])\n",
    "                DataDict1[\"direction\"].append(label[3])\n",
    "                DataDict1[\"command\"].append(label[4])\n",
    "                flip(label[0], label[1], label[2], label[3], label[4], True)\n",
    "            if key == 3:  # right\n",
    "                label.append(key)\n",
    "                DataDict3[\"image\"].append(label[0])\n",
    "                DataDict3[\"steer\"].append(label[1])\n",
    "                DataDict3[\"throttle\"].append(label[2])\n",
    "                DataDict3[\"direction\"].append(label[3])\n",
    "                DataDict3[\"command\"].append(label[4])\n",
    "                flip(label[0], label[1], label[2], label[3], label[4], False)\n",
    "            if key == 2:  # forward\n",
    "                label.append(key)\n",
    "                DataDict2[\"image\"].append(label[0])\n",
    "                DataDict2[\"steer\"].append(label[1])\n",
    "                DataDict2[\"throttle\"].append(label[2])\n",
    "                DataDict2[\"direction\"].append(label[3])\n",
    "                DataDict2[\"command\"].append(label[4])\n",
    "            if key == 0:  # continue\n",
    "                label.append(key)\n",
    "                DataDict0[\"image\"].append(label[0])\n",
    "                DataDict0[\"steer\"].append(label[1])\n",
    "                DataDict0[\"throttle\"].append(label[2])\n",
    "                DataDict0[\"direction\"].append(label[3])\n",
    "                DataDict0[\"command\"].append(label[4])\n",
    "            label.append(key)\n",
    "            DataDictAll[\"image\"].append(label[0])\n",
    "            DataDictAll[\"steer\"].append(label[1])\n",
    "            DataDictAll[\"throttle\"].append(label[2])\n",
    "            DataDictAll[\"direction\"].append(label[3])\n",
    "            DataDictAll[\"command\"].append(label[4])\n",
    "\n",
    "print(DataDict3)\n",
    "with open('DataDictAll.txt', 'wb') as f:\n",
    "    serializer.dump(DataDictAll, f)\n",
    "\n",
    "with open('DataDict0.txt', 'wb') as f:\n",
    "    serializer.dump(DataDict0, f)\n",
    "\n",
    "with open('DataDict1.txt', 'wb') as f:\n",
    "    serializer.dump(DataDict1, f)\n",
    "\n",
    "with open('DataDict2.txt', 'wb') as f:\n",
    "    serializer.dump(DataDict2, f)\n",
    "\n",
    "with open('DataDict3.txt', 'wb') as f:\n",
    "    serializer.dump(DataDict3, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(img_name, steer, throttle, direction, command, left = True):\n",
    "    \"\"\"\n",
    "    Function to flip an image including its values. If left = True, we flip from left to right.\n",
    "    If left = False, we flip from right to left.\n",
    "    \"\"\"\n",
    "    if left == True:\n",
    "        img_name = os.path.join(\"Bilder\", img_name)\n",
    "        image = io.imread(img_name)\n",
    "        image = np.flip(image,axis=1).copy()  # actual flipping is done here\n",
    "        img_name = img_name[:-4] + str(\"flip.png\")\n",
    "        im = Image.fromarray(image)\n",
    "        im.save(img_name)\n",
    "        DataDict3[\"image\"].append(img_name)\n",
    "        steer = steer * (-1)\n",
    "        DataDict3[\"steer\"].append(steer)\n",
    "        DataDict3[\"throttle\"].append(throttle)\n",
    "        if direction == 0:\n",
    "            direction = 2\n",
    "        if direction == 2:\n",
    "            direction = 0\n",
    "        DataDict3[\"direction\"].append(direction)\n",
    "        command = 3\n",
    "        DataDict3[\"command\"].append(command)\n",
    "\n",
    "    if left == False:\n",
    "        img_name = os.path.join(\"Bilder\", img_name)\n",
    "        image = io.imread(img_name)\n",
    "        image = np.flip(image,axis=1).copy()  # actual flipping is done here\n",
    "        img_name = img_name[:-4] + str(\"flip.png\")\n",
    "        im = Image.fromarray(image)\n",
    "        im.save(img_name)\n",
    "        DataDict1[\"image\"].append(img_name)\n",
    "        steer = steer * (-1)\n",
    "        DataDict1[\"steer\"].append(steer)\n",
    "        DataDict1[\"throttle\"].append(throttle)\n",
    "        if direction == 0:\n",
    "            direction = 2\n",
    "        if direction == 2:\n",
    "            direction = 0\n",
    "        DataDict1[\"direction\"].append(direction)\n",
    "        command = 1\n",
    "        DataDict1[\"command\"].append(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chose the DataSet you want to train the network on\n",
    "ChosenDataset = 'DataDict1.txt'\n",
    "\n",
    "with open(ChosenDataset, 'rb') as f:\n",
    "    dataset = serializer.load(f)\n",
    "\n",
    "class AISProject(Dataset):\n",
    "    \"\"\" AIS Project dataset.\"\"\"\n",
    "    def __init__(self, dictionary, root_dir, transform = None):\n",
    "\n",
    "        self.dictionary = pd.DataFrame.from_dict(dictionary)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        print(len(dictionary))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dictionary)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.dictionary.iloc[idx,0])\n",
    "        image = io.imread(img_name)\n",
    "        #steer = torch.tensor(self.dictionary.iloc[idx,1],dtype=torch.float32, requires_grad=True)\n",
    "        steer = torc.tensor(self.dictionary.iloc[idx,1],dtype=torch.long)\n",
    "        speed = torch.tensor(self.dictionary.iloc[idx,2],dtype = torch.float32)\n",
    "        direction = torch.tensor(self.dictionary.iloc[idx,3],dtype = torch.long)\n",
    "        command = torch.tensor(self.dictionary.iloc[idx,4],dtype = torch.uint8)\n",
    "        sample = {'image':image, 'steer': steer, 'speed': speed,'direction':direction, 'command':command }\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, steer, speed, direction, command = sample['image'], sample['steer'], sample['speed'], sample['direction'], sample['command']\n",
    "        image = image.transpose((2,0,1))\n",
    "        return {'image': torch.from_numpy(image), \n",
    "                'steer': torch.tensor(steer),\n",
    "               'speed': torch.tensor(speed),\n",
    "               'direction':torch.tensor(direction),\n",
    "               'command':torch.tensor(command)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    \"\"\"Class to crop our data. (Modified RandomCrop, so that the crop isn't random anymore)\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        #new_h, new_w = output_size\n",
    "        new_h = 64\n",
    "        image = image[new_h:h, 0:w]\n",
    "        #show_image to test whether the pictures are cropped as we wish\n",
    "        #show_image(image)\n",
    "        sample['image'] = image\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure()\\nshow_image(io.imread(os.path.join('Bilder/',img_name)))\\nplt.show()\\n\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_image(image):\n",
    "    plt.imshow(image)\n",
    "\n",
    "'''\n",
    "plt.figure()\n",
    "show_image(io.imread(os.path.join('Bilder/',img_name)))\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "0 {'image': tensor([[[ 37,  36,  35,  ...,  45,  44,  44],\n",
      "         [ 44,  44,  45,  ...,  42,  41,  42],\n",
      "         [163, 164, 164,  ...,  49,  48,  46],\n",
      "         ...,\n",
      "         [  4,   3,   4,  ..., 141, 141, 142],\n",
      "         [  5,   6,   5,  ..., 142, 141, 140],\n",
      "         [  4,   5,   4,  ..., 141, 140, 140]],\n",
      "\n",
      "        [[ 41,  41,  39,  ...,  49,  48,  48],\n",
      "         [ 49,  48,  49,  ...,  47,  45,  46],\n",
      "         [164, 165, 164,  ...,  53,  52,  50],\n",
      "         ...,\n",
      "         [  5,   5,   6,  ..., 146, 146, 147],\n",
      "         [  7,   7,   7,  ..., 146, 145, 144],\n",
      "         [  6,   7,   6,  ..., 145, 145, 144]],\n",
      "\n",
      "        [[ 27,  27,  26,  ...,  33,  33,  32],\n",
      "         [ 35,  35,  36,  ...,  32,  31,  32],\n",
      "         [155, 157, 157,  ...,  39,  38,  36],\n",
      "         ...,\n",
      "         [  4,   3,   4,  ..., 143, 142, 143],\n",
      "         [  7,   8,   7,  ..., 143, 142, 141],\n",
      "         [  5,   6,   6,  ..., 143, 142, 142]]], dtype=torch.uint8), 'steer': tensor(0), 'speed': tensor(0.1000), 'direction': tensor(1), 'command': tensor(1, dtype=torch.uint8)}\n",
      "1 {'image': tensor([[[ 16,  16,  15,  ...,  21,  20,  21],\n",
      "         [ 23,  24,  24,  ...,  21,  21,  20],\n",
      "         [138, 139, 138,  ...,  27,  26,  23],\n",
      "         ...,\n",
      "         [  1,   0,   0,  ..., 112, 112, 111],\n",
      "         [  0,   1,   0,  ..., 113, 112, 112],\n",
      "         [  0,   0,   0,  ..., 112, 113, 111]],\n",
      "\n",
      "        [[ 19,  19,  18,  ...,  24,  23,  24],\n",
      "         [ 26,  27,  28,  ...,  25,  24,  24],\n",
      "         [138, 139, 138,  ...,  30,  29,  26],\n",
      "         ...,\n",
      "         [  1,   0,   1,  ..., 119, 118, 117],\n",
      "         [  0,   1,   1,  ..., 118, 118, 118],\n",
      "         [  1,   0,   0,  ..., 119, 119, 117]],\n",
      "\n",
      "        [[ 10,  10,   9,  ...,  13,  13,  13],\n",
      "         [ 16,  17,  17,  ...,  14,  13,  12],\n",
      "         [130, 131, 130,  ...,  19,  19,  15],\n",
      "         ...,\n",
      "         [  1,   0,   0,  ..., 116, 116, 115],\n",
      "         [  0,   1,   0,  ..., 114, 115, 113],\n",
      "         [  0,   0,   0,  ..., 114, 114, 113]]], dtype=torch.uint8), 'steer': tensor(0), 'speed': tensor(0.1000), 'direction': tensor(1), 'command': tensor(1, dtype=torch.uint8)}\n",
      "2 {'image': tensor([[[ 18,  18,  17,  ...,  23,  23,  22],\n",
      "         [ 24,  25,  25,  ...,  23,  23,  22],\n",
      "         [141, 141, 141,  ...,  29,  29,  25],\n",
      "         ...,\n",
      "         [  0,   1,   0,  ..., 112, 109, 112],\n",
      "         [  0,   0,   0,  ..., 112, 112, 114],\n",
      "         [  0,   0,   1,  ..., 117, 114, 116]],\n",
      "\n",
      "        [[ 21,  21,  21,  ...,  26,  26,  25],\n",
      "         [ 27,  29,  28,  ...,  26,  26,  26],\n",
      "         [141, 141, 141,  ...,  32,  33,  28],\n",
      "         ...,\n",
      "         [  0,   1,   1,  ..., 118, 116, 118],\n",
      "         [  0,   0,   0,  ..., 118, 119, 120],\n",
      "         [  0,   0,   1,  ..., 123, 120, 122]],\n",
      "\n",
      "        [[ 11,  11,  10,  ...,  15,  15,  14],\n",
      "         [ 17,  18,  17,  ...,  15,  15,  15],\n",
      "         [133, 133, 133,  ...,  22,  21,  17],\n",
      "         ...,\n",
      "         [  0,   1,   0,  ..., 115, 113, 116],\n",
      "         [  0,   0,   0,  ..., 115, 116, 118],\n",
      "         [  0,   0,   1,  ..., 120, 117, 118]]], dtype=torch.uint8), 'steer': tensor(0), 'speed': tensor(0.1000), 'direction': tensor(0), 'command': tensor(1, dtype=torch.uint8)}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "transformed_dataset = AISProject(dictionary = dataset, root_dir='Bilder/', \n",
    "                                transform = transforms.Compose([RandomCrop(), ToTensor(),\n",
    "                                                               transforms.ColorJitter()]))\n",
    "transformed_dataset2 = AISProject(dictionary = dataset, root_dir='Bilder/', \n",
    "                                transform = transforms.Compose([ToTensor()]))\n",
    "\n",
    "for i in range(len(transformed_dataset)):\n",
    "    sample = transformed_dataset[i]\n",
    "    \n",
    "    print(i, sample)\n",
    "    if i == 2:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef show_labels_batch(sample_batched):\\n    \"\"\"Show image with labels for a batch of samples.\"\"\"\\n    images_batch, labels_batch =         sample_batched[\\'image\\'], sample_batched[\\'steer\\']\\n    batch_size = len(images_batch)\\n    im_size = images_batch.size(2)\\n    \\n    grid = utils.make_grid(images_batch)\\n    plt.imshow(grid.numpy().transpose((1,2,0)))\\n\\n\\n\\nfor i_batch, sample_batched in enumerate(TrainData):\\n    print(i_batch, sample_batched[\\'image\\'].size(), \\n         sample_batched[\\'steer\\'].size())\\n\\n    if i_batch == 1:\\n        plt.figure(figsize=(40,40))\\n        show_labels_batch(sample_batched)\\n        plt.axis(\\'off\\')\\n        plt.ioff()\\n        plt.show()\\n        break\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData = DataLoader(transformed_dataset, batch_size=32, \n",
    "                        shuffle=False, pin_memory=True)\n",
    "TestData = DataLoader(transformed_dataset2, batch_size=1, \n",
    "                        shuffle=False, pin_memory=True)\n",
    "'''\n",
    "for batch_idx, dataset in enumerate(TrainData):\n",
    "    print(batch_idx)\n",
    "    print(dataset['image'].size())\n",
    "    print(dataset['command'].size())\n",
    "    print(dataset['direction'])\n",
    "    if batch_idx == 3:\n",
    "        break\n",
    "'''\n",
    "'''\n",
    "def show_labels_batch(sample_batched):\n",
    "    \"\"\"Show image with labels for a batch of samples.\"\"\"\n",
    "    images_batch, labels_batch = \\\n",
    "        sample_batched['image'], sample_batched['steer']\n",
    "    batch_size = len(images_batch)\n",
    "    im_size = images_batch.size(2)\n",
    "    \n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imshow(grid.numpy().transpose((1,2,0)))\n",
    "\n",
    "\n",
    "\n",
    "for i_batch, sample_batched in enumerate(TrainData):\n",
    "    print(i_batch, sample_batched['image'].size(), \n",
    "         sample_batched['steer'].size())\n",
    "\n",
    "    if i_batch == 1:\n",
    "        plt.figure(figsize=(40,40))\n",
    "        show_labels_batch(sample_batched)\n",
    "        plt.axis('off')\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "        break\n",
    "'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Network with branches '''\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "# Definition of the network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)    # FYI: In the lecture I forgot to add the padding, thats why the feature size calculation was wrong\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv8_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(81920, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        #here we start the branching\n",
    "        # Brach 1\n",
    "        self.fc1B1 = nn.Linear(512, 256)\n",
    "        self.fc2B1 = nn.Linear(256, 256)\n",
    "        self.fc3B1 = nn.Linear(256, 3) # the output is direction\n",
    "        \n",
    "        #ToDo: implement other branches\n",
    "        '''\n",
    "        # Brach 2\n",
    "        self.fcB2 = nn.Linear(512, 256)\n",
    "        self.fcB2 = nn.Linear(256, 256)\n",
    "        self.fcB2 = nn.Linear(256, 3) # the output is direction\n",
    "        # Brach 3\n",
    "        self.fcB3 = nn.Linear(512, 256)\n",
    "        self.fcB3 = nn.Linear(256, 3) # the output is direction\n",
    "        # Brach 4\n",
    "        self.fcB4 = nn.Linear(512, 256)\n",
    "        self.fcB4 = nn.Linear(256, 3) # the output is direction\n",
    "        '''\n",
    "\n",
    "    def forward(self, x, command):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)),2)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8_drop(self.conv8(x)))\n",
    "        x = F.max_pool2d(x,4)\n",
    "        x = x.view(-1, 81920)   # Flatten data for fully connected layer. Input size is 28*28, we have 2 pooling layers so we pool the spatial size down to 7*7. With 20 feature maps as the output of the previous conv we have in total 7x7x20 = 980 features.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        # choosing the branch\n",
    "        if command == 0:\n",
    "            x = F.relu(self.fc1B1(x))\n",
    "            x = F.relu(self.fc2B1(x))\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = self.fc3B1(x)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "\n",
    "        \n",
    "        '''\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x),2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv4(x),2))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv8_drop(self.conv8(x)), 2))\n",
    "        x = x.view(-1, 327680)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "        '''\n",
    "# We create the network, shift it on the GPU and define a optimizer on its parameters\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function trains the neural network for one epoch\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(TrainData):\n",
    "        # Move the input and target data on the GPU\n",
    "        sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "        #sample['direction'] = sample['direction'].type('torch.FloatTensor')\n",
    "        \n",
    "        data, target = sample['image'].to(device), sample['direction'].to(device)  # .cuda() works too instead of .to(device)\n",
    "        command = sample['command']\n",
    "        if command[0] == 1:\n",
    "            # Zero out gradients from previous step\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data, 0)\n",
    "            #print(\"target\")\n",
    "            #print(target.type())\n",
    "            #output = output.squeeze()\n",
    "            loss = F.nll_loss(output, target)\n",
    "            #loss = F.smooth_l1_loss(output, target)\n",
    "            #loss = loss(output, target)\n",
    "            loss.backward()\n",
    "            # Adjusting the parameters according to the loss function\n",
    "            optimizer.step()\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(TrainData.dataset),\n",
    "                    100. * batch_idx / len(TrainData), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target label is : 0\n",
      "Predicted label is : 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    count2 = 0\n",
    "    with torch.no_grad():\n",
    "        for sample in TestData:\n",
    "            datacv = sample['image']\n",
    "            # Move the input and target data on the GPU\n",
    "            sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "            \n",
    "            #sample['direction'] = sample['direction'].type('torch.FloatTensor')\n",
    "            data, target = sample['image'].to(device), sample['direction'].to(device)  # .cuda() works too instead of .to(device)\n",
    "            command = sample['command']\n",
    "            if command == 1:\n",
    "                output = model(data, 0)\n",
    "                #output = output.squeeze()\n",
    "                #print(output)\n",
    "                #if target\n",
    "                test_loss += F.nll_loss(output, target).item()\n",
    "                #test_loss += F.smooth_l1_loss(output, target, size_average=False).item() # sum up batch loss\n",
    "                #test_loss += loss(output, target).item()\n",
    "                pred = output.max(1, keepdim=True)[1]\n",
    "                #pred = output # get the index of the max log-probability\n",
    "                \n",
    "                if not pred.eq(target.view_as(pred)):   ## If you just want so see the failing examples\n",
    "                    datacv = datacv.cpu()\n",
    "                    grid = utils.make_grid(datacv)\n",
    "                    grid = grid.numpy().transpose((1,2,0))\n",
    "                    #plt.imshow(grid)\n",
    "                    #cv_mat = data.cpu().data.squeeze().numpy()\n",
    "                    #cv_mat = cv2.resize(cv_mat, (128, 640))\n",
    "                    #plt.figure(figsize=(320,64))\n",
    "                    cv2.imshow(\"test image\", grid)\n",
    "                    #plt.axis('off')\n",
    "                    #plt.ioff()\n",
    "                    #plt.show()\n",
    "                    print(\"Target label is : %d\" % target.cpu().item())\n",
    "                    print(\"Predicted label is : %d\" % (pred.cpu().data.item()))\n",
    "                    cv2.waitKey()\n",
    "                 \n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= len(TestData.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(TestData.dataset),\n",
    "        100. * correct / len(TestData.dataset)))\n",
    "'''\n",
    "num_train_epochs = 40\n",
    "for epoch in range(1, num_train_epochs + 1):\n",
    "    train(epoch)\n",
    "'''\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.L1Loss()\n",
    "input1 = torch.tensor([-1.88],requires_grad=True,dtype=torch.float32)\n",
    "input2 = torch.tensor([-1.88],requires_grad=True,dtype=torch.float32)\n",
    "target = torch.tensor([1],dtype=torch.float64)\n",
    "b = input2.max(0, keepdim=True)[0]\n",
    "#output = loss(input1,input2)\n",
    "print(b)\n",
    "#output.backward()\n",
    "#print(output)\n",
    "print(input1.eq(input2).sum().item())\n",
    "\n",
    "#x = output.max(0,keepdim=True)[1]\n",
    "m = input2.view_as(0)\n",
    "print(\"m\")\n",
    "print(m)\n",
    "\n",
    "correct = output.eq(target.view_as(output)).sum().item()\n",
    "print(correct)\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "all = 0\n",
    "a = torch.tensor([0],dtype=torch.float64)\n",
    "for batch_idx, sample in enumerate(dataloader2):\n",
    "    sample = sample.to(device)\n",
    "    print(sample['steer'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This function trains the neural network for one epoch\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(dataloader):\n",
    "        # Move the input and target data on the GPU\n",
    "        sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "        sample['steer'] = sample['steer'].type('torch.FloatTensor')\n",
    "        \n",
    "        data, target = sample['image'].to(device), sample['steer'].to(device)  # .cuda() works too instead of .to(device)\n",
    "        #loss = nn.L1Loss()\n",
    "        # Zero out gradients from previous step\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #print(output.type())\n",
    "        #print(\"target\")\n",
    "        #print(target.type())\n",
    "        #output = output.squeeze()\n",
    "        #loss = F.nll_loss(output, target)\n",
    "        loss = F.smooth_l1_loss(output, target)\n",
    "        #loss = loss(output, target)\n",
    "        loss.backward()\n",
    "        # Adjusting the parameters according to the loss function\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(dataloader.dataset),\n",
    "                100. * batch_idx / len(dataloader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = torch.device(\"cpu\")\n",
    "# Definition of the network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)    # FYI: In the lecture I forgot to add the padding, thats why the feature size calculation was wrong\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv8_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(327680, 50)\n",
    "        self.fc2 = nn.Linear(50, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)),2)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8_drop(self.conv8(x)))\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = x.view(-1, 327680)   # Flatten data for fully connected layer. Input size is 28*28, we have 2 pooling layers so we pool the spatial size down to 7*7. With 20 feature maps as the output of the previous conv we have in total 7x7x20 = 980 features.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "        '''\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x),2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv4(x),2))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv8_drop(self.conv8(x)), 2))\n",
    "        x = x.view(-1, 327680)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "        '''\n",
    "# We create the network, shift it on the GPU and define a optimizer on its parameters\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This function trains the neural network for one epoch\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(dataloader):\n",
    "        # Move the input and target data on the GPU\n",
    "        sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "        sample['steer'] = sample['steer'].type('torch.FloatTensor')\n",
    "        \n",
    "        data, target = sample['image'].to(device), sample['steer'].to(device)  # .cuda() works too instead of .to(device)\n",
    "        #loss = nn.L1Loss()\n",
    "        # Zero out gradients from previous step\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #print(output.type())\n",
    "        #print(\"target\")\n",
    "        #print(target.type())\n",
    "        #output = output.squeeze()\n",
    "        #loss = F.nll_loss(output, target)\n",
    "        loss = F.smooth_l1_loss(output, target)\n",
    "        #loss = loss(output, target)\n",
    "        loss.backward()\n",
    "        # Adjusting the parameters according to the loss function\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(dataloader.dataset),\n",
    "                100. * batch_idx / len(dataloader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for sample in dataloader2:\n",
    "            # Move the input and target data on the GPU\n",
    "            sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "            sample['steer'] = sample['steer'].type('torch.FloatTensor')\n",
    "            #loss = nn.L1Loss()\n",
    "            data, target = sample['image'].to(device), sample['steer'].to(device)  # .cuda() works too instead of .to(device)\n",
    "            output = model(data)\n",
    "            #output = output.squeeze()\n",
    "            #print(output)\n",
    "            #test_loss += F.nll_loss(output, target).item()\n",
    "            test_loss += F.smooth_l1_loss(output, target, size_average=False).item() # sum up batch loss\n",
    "            #test_loss += loss(output, target).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            #print(pred)\n",
    "            print(target)\n",
    "            #pred = output # get the index of the max log-probability\n",
    "            '''\n",
    "            if not pred.eq(target.view_as(pred)):   ## If you just want so see the failing examples\n",
    "                cv_mat = data.cuda().data.squeeze().numpy()\n",
    "                cv_mat = cv2.resize(cv_mat, (400, 400))\n",
    "                cv2.imshow(\"test image\", cv_mat)\n",
    "                print(\"Target label is : %d\" % target.cuda().item())\n",
    "                print(\"Predicted label is : %d\" % (pred.cuda().data.item()))\n",
    "                cv2.waitKey()\n",
    "            '''\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= len(dataloader2.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(dataloader2.dataset),\n",
    "        100. * correct / len(dataloader2.dataset)))\n",
    "\n",
    "num_train_epochs = 2\n",
    "for epoch in range(1, num_train_epochs + 1):\n",
    "    train(epoch)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

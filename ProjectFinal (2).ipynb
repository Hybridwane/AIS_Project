{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch.nn.functional as F\n",
    "torch.set_printoptions(linewidth=120)\n",
    "\n",
    "import pickle as serializer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this function seperates the different commands in 4 different dictionaries\n",
    "# DataDict0 is for command0 'continue'\n",
    "# DataDict1 is for command1 'left' .usw\n",
    "\n",
    "with open('dataset.txt', 'rb') as f:\n",
    "    dataset = serializer.load(f)\n",
    "    \n",
    "DataDictAll = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "DataDict0 = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "DataDict1 = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "DataDict2 = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "DataDict3 = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "\n",
    "keys = dataset.keys()\n",
    "for key in keys:\n",
    "    for label in dataset[key]:\n",
    "        #DataDict[\"image\"].append(label[0])\n",
    "        if label[3] == 'left':\n",
    "            label[3] = 0\n",
    "        if label[3] == 'right':\n",
    "            label[3] = 2\n",
    "        if label[3] == 'forward':\n",
    "            label[3] = 1\n",
    "        if key == 'left':\n",
    "            key = 1\n",
    "            '''\n",
    "            label.append(key)\n",
    "            DataDict1[\"image\"].append(label[0])\n",
    "            DataDict1[\"steer\"].append(label[1])\n",
    "            DataDict1[\"throttle\"].append(label[2])\n",
    "            DataDict1[\"direction\"].append(label[3])\n",
    "            DataDict1[\"command\"].append(label[4])\n",
    "            '''\n",
    "        if key == 'right':\n",
    "            key = 3\n",
    "            '''\n",
    "            label.append(key)\n",
    "            DataDict3[\"image\"].append(label[0])\n",
    "            DataDict3[\"steer\"].append(label[1])\n",
    "            DataDict3[\"throttle\"].append(label[2])\n",
    "            DataDict3[\"direction\"].append(label[3])\n",
    "            DataDict3[\"command\"].append(label[4])\n",
    "            '''\n",
    "        if key == 'forward':\n",
    "            key = 2\n",
    "            '''\n",
    "            label.append(key)\n",
    "            DataDict2[\"image\"].append(label[0])\n",
    "            DataDict2[\"steer\"].append(label[1])\n",
    "            DataDict2[\"throttle\"].append(label[2])\n",
    "            DataDict2[\"direction\"].append(label[3])\n",
    "            DataDict2[\"command\"].append(label[4])\n",
    "            '''\n",
    "        if key == 'continue':\n",
    "            key = 0\n",
    "            '''\n",
    "            label.append(key)\n",
    "            DataDict0[\"image\"].append(label[0])\n",
    "            DataDict0[\"steer\"].append(label[1])\n",
    "            DataDict0[\"throttle\"].append(label[2])\n",
    "            DataDict0[\"direction\"].append(label[3])\n",
    "            DataDict0[\"command\"].append(label[4])\n",
    "            '''\n",
    "        gut = 'Bilder/'+ label[0]\n",
    "        if os.path.exists(gut):\n",
    "            if key == 1:\n",
    "                label.append(key)\n",
    "                DataDict1[\"image\"].append(label[0])\n",
    "                DataDict1[\"steer\"].append(label[1])\n",
    "                DataDict1[\"throttle\"].append(label[2])\n",
    "                DataDict1[\"direction\"].append(label[3])\n",
    "                DataDict1[\"command\"].append(label[4])\n",
    "            if key == 3:\n",
    "                label.append(key)\n",
    "                DataDict3[\"image\"].append(label[0])\n",
    "                DataDict3[\"steer\"].append(label[1])\n",
    "                DataDict3[\"throttle\"].append(label[2])\n",
    "                DataDict3[\"direction\"].append(label[3])\n",
    "                DataDict3[\"command\"].append(label[4])\n",
    "            if key == 2:\n",
    "                label.append(key)\n",
    "                DataDict2[\"image\"].append(label[0])\n",
    "                DataDict2[\"steer\"].append(label[1])\n",
    "                DataDict2[\"throttle\"].append(label[2])\n",
    "                DataDict2[\"direction\"].append(label[3])\n",
    "                DataDict2[\"command\"].append(label[4])\n",
    "            if key == 0:\n",
    "                label.append(key)\n",
    "                DataDict0[\"image\"].append(label[0])\n",
    "                DataDict0[\"steer\"].append(label[1])\n",
    "                DataDict0[\"throttle\"].append(label[2])\n",
    "                DataDict0[\"direction\"].append(label[3])\n",
    "                DataDict0[\"command\"].append(label[4])\n",
    "            label.append(key)\n",
    "            DataDictAll[\"image\"].append(label[0])\n",
    "            DataDictAll[\"steer\"].append(label[1])\n",
    "            DataDictAll[\"throttle\"].append(label[2])\n",
    "            DataDictAll[\"direction\"].append(label[3])\n",
    "            DataDictAll[\"command\"].append(label[4])\n",
    "\n",
    "print(DataDict0)\n",
    "with open('DataDictAll.txt', 'wb') as f:\n",
    "    serializer.dump(DataDictAll, f)\n",
    "\n",
    "with open('DataDict0.txt', 'wb') as f:\n",
    "    serializer.dump(DataDict0, f)\n",
    "\n",
    "with open('DataDict1.txt', 'wb') as f:\n",
    "    serializer.dump(DataDict1, f)\n",
    "\n",
    "with open('DataDict2.txt', 'wb') as f:\n",
    "    serializer.dump(DataDict2, f)\n",
    "\n",
    "with open('DataDict3.txt', 'wb') as f:\n",
    "    serializer.dump(DataDict3, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chose the DataSet you want to train the network on\n",
    "ChosenDataset = 'DataDict1.txt'\n",
    "\n",
    "with open(ChosenDataset, 'rb') as f:\n",
    "    dataset = serializer.load(f)\n",
    "\n",
    "class AISProject(Dataset):\n",
    "    \"\"\" AIS Project dataset.\"\"\"\n",
    "    def __init__(self, dictionary, root_dir, transform = None):\n",
    "\n",
    "        self.dictionary = pd.DataFrame.from_dict(dictionary)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        print(len(dictionary))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dictionary)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.dictionary.iloc[idx,0])\n",
    "        image = io.imread(img_name)\n",
    "        #steer = torch.tensor(self.dictionary.iloc[idx,1],dtype=torch.float32, requires_grad=True)\n",
    "        steer = torch.tensor(self.dictionary.iloc[idx,1],dtype=torch.long)\n",
    "        speed = torch.tensor(self.dictionary.iloc[idx,2],dtype = torch.float32)\n",
    "        direction = torch.tensor(self.dictionary.iloc[idx,3],dtype = torch.long)\n",
    "        command = torch.tensor(self.dictionary.iloc[idx,4],dtype = torch.uint8)\n",
    "        sample = {'image':image, 'steer': steer, 'speed': speed,'direction':direction, 'command':command }\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, steer, speed, direction, command = sample['image'], sample['steer'], sample['speed'], sample['direction'], sample['command']\n",
    "        image = image.transpose((2,0,1))\n",
    "        return {'image': torch.from_numpy(image), \n",
    "                'steer': torch.tensor(steer),\n",
    "               'speed': torch.tensor(speed),\n",
    "               'direction':torch.tensor(direction),\n",
    "               'command':torch.tensor(command)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    \"\"\"Class to crop our data. (Modified RandomCrop, so that the crop isn't random anymore)\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        #new_h, new_w = output_size\n",
    "        new_h = 64\n",
    "        image = image[new_h:h, 0:w]\n",
    "        #show_image to test whether the pictures are cropped as we wish\n",
    "        #show_image(image)\n",
    "        sample['image'] = image\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomHorizontalFlip(object):\n",
    "    \"\"\"Class to flip our data horizontally. Only done for left and right turns. (Modified RandomHorizontalFlip,\n",
    "    so that it isn't random anymore)\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            sample.\n",
    "\n",
    "        Returns:\n",
    "            Horizontally flipped sample with adjusted steer and direction. (Must command also be modified?) \n",
    "        \"\"\"\n",
    "        image, steer, direction, command = sample['image'], sample['steer'], sample['direction'], sample['command']\n",
    "        if direction == 1:\n",
    "            dataset.update(sample)  # This saves the 'old' image. Now we can change it to the opposite direction. Probably doesn't work properly yet.\n",
    "            image = np.flip(image,axis=1).copy()\n",
    "            direction = 2\n",
    "            steer = steer*(-1)\n",
    "            if command == 1:\n",
    "                command = 3\n",
    "            if command == 3:\n",
    "                command = 1\n",
    "        elif direction == 2:\n",
    "            dataset.update(sample)\n",
    "            image = np.flip(image,axis=1).copy()\n",
    "            direction = 1\n",
    "            steer = steer*(-1)\n",
    "            if command == 1:\n",
    "                command = 3\n",
    "            if command == 3:\n",
    "                command = 1\n",
    "        #show_image(image)\n",
    "        sample['image'] = image\n",
    "        sample['steer'] = steer\n",
    "        sample['direction'] = direction\n",
    "        sample['command'] = command\n",
    "        return sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eventual space for a modified ColorJitter class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure()\\nshow_image(io.imread(os.path.join('Bilder/',img_name)))\\nplt.show()\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_image(image):\n",
    "    plt.imshow(image)\n",
    "\n",
    "'''\n",
    "plt.figure()\n",
    "show_image(io.imread(os.path.join('Bilder/',img_name)))\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "0 {'image': tensor([[[ 44,  44,  45,  ...,  35,  36,  37],\n",
      "         [ 42,  41,  42,  ...,  45,  44,  44],\n",
      "         [ 46,  48,  49,  ..., 164, 164, 163],\n",
      "         ...,\n",
      "         [142, 141, 141,  ...,   4,   3,   4],\n",
      "         [140, 141, 142,  ...,   5,   6,   5],\n",
      "         [140, 140, 141,  ...,   4,   5,   4]],\n",
      "\n",
      "        [[ 48,  48,  49,  ...,  39,  41,  41],\n",
      "         [ 46,  45,  47,  ...,  49,  48,  49],\n",
      "         [ 50,  52,  53,  ..., 164, 165, 164],\n",
      "         ...,\n",
      "         [147, 146, 146,  ...,   6,   5,   5],\n",
      "         [144, 145, 146,  ...,   7,   7,   7],\n",
      "         [144, 145, 145,  ...,   6,   7,   6]],\n",
      "\n",
      "        [[ 32,  33,  33,  ...,  26,  27,  27],\n",
      "         [ 32,  31,  32,  ...,  36,  35,  35],\n",
      "         [ 36,  38,  39,  ..., 157, 157, 155],\n",
      "         ...,\n",
      "         [143, 142, 143,  ...,   4,   3,   4],\n",
      "         [141, 142, 143,  ...,   7,   8,   7],\n",
      "         [142, 142, 143,  ...,   6,   6,   5]]], dtype=torch.uint8), 'steer': tensor(0), 'speed': tensor(0.1000), 'direction': tensor(2), 'command': tensor(1)}\n",
      "1 {'image': tensor([[[ 21,  20,  21,  ...,  15,  16,  16],\n",
      "         [ 20,  21,  21,  ...,  24,  24,  23],\n",
      "         [ 23,  26,  27,  ..., 138, 139, 138],\n",
      "         ...,\n",
      "         [111, 112, 112,  ...,   0,   0,   1],\n",
      "         [112, 112, 113,  ...,   0,   1,   0],\n",
      "         [111, 113, 112,  ...,   0,   0,   0]],\n",
      "\n",
      "        [[ 24,  23,  24,  ...,  18,  19,  19],\n",
      "         [ 24,  24,  25,  ...,  28,  27,  26],\n",
      "         [ 26,  29,  30,  ..., 138, 139, 138],\n",
      "         ...,\n",
      "         [117, 118, 119,  ...,   1,   0,   1],\n",
      "         [118, 118, 118,  ...,   1,   1,   0],\n",
      "         [117, 119, 119,  ...,   0,   0,   1]],\n",
      "\n",
      "        [[ 13,  13,  13,  ...,   9,  10,  10],\n",
      "         [ 12,  13,  14,  ...,  17,  17,  16],\n",
      "         [ 15,  19,  19,  ..., 130, 131, 130],\n",
      "         ...,\n",
      "         [115, 116, 116,  ...,   0,   0,   1],\n",
      "         [113, 115, 114,  ...,   0,   1,   0],\n",
      "         [113, 114, 114,  ...,   0,   0,   0]]], dtype=torch.uint8), 'steer': tensor(0), 'speed': tensor(0.1000), 'direction': tensor(2), 'command': tensor(1)}\n"
     ]
    }
   ],
   "source": [
    "transformed_dataset = AISProject(dictionary = dataset, root_dir='Bilder/', \n",
    "                                transform = transforms.Compose([RandomCrop(), RandomHorizontalFlip(), ToTensor(),\n",
    "                                                               transforms.ColorJitter()]))\n",
    "transformed_dataset2 = AISProject(dictionary = dataset, root_dir='Bilder/', \n",
    "                                transform = transforms.Compose([ToTensor()]))\n",
    "\n",
    "for i in range(len(transformed_dataset)):\n",
    "    sample = transformed_dataset[i]\n",
    "    \n",
    "    print(i, sample)\n",
    "    if i == 1:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef show_labels_batch(sample_batched):\\n    \"\"\"Show image with labels for a batch of samples.\"\"\"\\n    images_batch, labels_batch =         sample_batched[\\'image\\'], sample_batched[\\'steer\\']\\n    batch_size = len(images_batch)\\n    im_size = images_batch.size(2)\\n    \\n    grid = utils.make_grid(images_batch)\\n    plt.imshow(grid.numpy().transpose((1,2,0)))\\n\\n\\n\\nfor i_batch, sample_batched in enumerate(TrainData):\\n    print(i_batch, sample_batched[\\'image\\'].size(), \\n         sample_batched[\\'steer\\'].size())\\n\\n    if i_batch == 1:\\n        plt.figure(figsize=(40,40))\\n        show_labels_batch(sample_batched)\\n        plt.axis(\\'off\\')\\n        plt.ioff()\\n        plt.show()\\n        break\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData = DataLoader(transformed_dataset, batch_size=32, \n",
    "                        shuffle=False, pin_memory=True)\n",
    "TestData = DataLoader(transformed_dataset2, batch_size=1, \n",
    "                        shuffle=False, pin_memory=True)\n",
    "'''\n",
    "for batch_idx, dataset in enumerate(TrainData):\n",
    "    print(batch_idx)\n",
    "    print(dataset['image'].size())\n",
    "    print(dataset['command'].size())\n",
    "    print(dataset['direction'])\n",
    "    if batch_idx == 3:\n",
    "        break\n",
    "'''\n",
    "'''\n",
    "def show_labels_batch(sample_batched):\n",
    "    \"\"\"Show image with labels for a batch of samples.\"\"\"\n",
    "    images_batch, labels_batch = \\\n",
    "        sample_batched['image'], sample_batched['steer']\n",
    "    batch_size = len(images_batch)\n",
    "    im_size = images_batch.size(2)\n",
    "    \n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imshow(grid.numpy().transpose((1,2,0)))\n",
    "\n",
    "\n",
    "\n",
    "for i_batch, sample_batched in enumerate(TrainData):\n",
    "    print(i_batch, sample_batched['image'].size(), \n",
    "         sample_batched['steer'].size())\n",
    "\n",
    "    if i_batch == 1:\n",
    "        plt.figure(figsize=(40,40))\n",
    "        show_labels_batch(sample_batched)\n",
    "        plt.axis('off')\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "        break\n",
    "'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Network with branches '''\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "# Definition of the network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)    # FYI: In the lecture I forgot to add the padding, thats why the feature size calculation was wrong\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv8_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(81920, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        #here we start the branching\n",
    "        # Brach 1\n",
    "        self.fc1B1 = nn.Linear(512, 256)\n",
    "        self.fc2B1 = nn.Linear(256, 256)\n",
    "        self.fc3B1 = nn.Linear(256, 3) # the output is direction\n",
    "        \n",
    "        #ToDo: implement other branches\n",
    "        '''\n",
    "        # Brach 2\n",
    "        self.fcB2 = nn.Linear(512, 256)\n",
    "        self.fcB2 = nn.Linear(256, 256)\n",
    "        self.fcB2 = nn.Linear(256, 3) # the output is direction\n",
    "        # Brach 3\n",
    "        self.fcB3 = nn.Linear(512, 256)\n",
    "        self.fcB3 = nn.Linear(256, 3) # the output is direction\n",
    "        # Brach 4\n",
    "        self.fcB4 = nn.Linear(512, 256)\n",
    "        self.fcB4 = nn.Linear(256, 3) # the output is direction\n",
    "        '''\n",
    "\n",
    "    def forward(self, x, command):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)),2)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8_drop(self.conv8(x)))\n",
    "        x = F.max_pool2d(x,4)\n",
    "        x = x.view(-1, 81920)   # Flatten data for fully connected layer. Input size is 28*28, we have 2 pooling layers so we pool the spatial size down to 7*7. With 20 feature maps as the output of the previous conv we have in total 7x7x20 = 980 features.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        # choosing the branch\n",
    "        if command == 0:\n",
    "            x = F.relu(self.fc1B1(x))\n",
    "            x = F.relu(self.fc2B1(x))\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = self.fc3B1(x)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "\n",
    "        \n",
    "        '''\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x),2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv4(x),2))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv8_drop(self.conv8(x)), 2))\n",
    "        x = x.view(-1, 327680)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "        '''\n",
    "# We create the network, shift it on the GPU and define a optimizer on its parameters\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function trains the neural network for one epoch\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(TrainData):\n",
    "        # Move the input and target data on the GPU\n",
    "        sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "        #sample['direction'] = sample['direction'].type('torch.FloatTensor')\n",
    "        \n",
    "        data, target = sample['image'].to(device), sample['direction'].to(device)  # .cuda() works too instead of .to(device)\n",
    "        command = sample['command']\n",
    "        if command[0] == 1:\n",
    "            # Zero out gradients from previous step\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data, 0)\n",
    "            #print(\"target\")\n",
    "            #print(target.type())\n",
    "            #output = output.squeeze()\n",
    "            loss = F.nll_loss(output, target)\n",
    "            #loss = F.smooth_l1_loss(output, target)\n",
    "            #loss = loss(output, target)\n",
    "            loss.backward()\n",
    "            # Adjusting the parameters according to the loss function\n",
    "            optimizer.step()\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(TrainData.dataset),\n",
    "                    100. * batch_idx / len(TrainData), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target label is : 0\n",
      "Predicted label is : 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    count2 = 0\n",
    "    with torch.no_grad():\n",
    "        for sample in TestData:\n",
    "            datacv = sample['image']\n",
    "            # Move the input and target data on the GPU\n",
    "            sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "            \n",
    "            #sample['direction'] = sample['direction'].type('torch.FloatTensor')\n",
    "            data, target = sample['image'].to(device), sample['direction'].to(device)  # .cuda() works too instead of .to(device)\n",
    "            command = sample['command']\n",
    "            if command == 1:\n",
    "                output = model(data, 0)\n",
    "                #output = output.squeeze()\n",
    "                #print(output)\n",
    "                #if target\n",
    "                test_loss += F.nll_loss(output, target).item()\n",
    "                #test_loss += F.smooth_l1_loss(output, target, size_average=False).item() # sum up batch loss\n",
    "                #test_loss += loss(output, target).item()\n",
    "                pred = output.max(1, keepdim=True)[1]\n",
    "                #pred = output # get the index of the max log-probability\n",
    "                \n",
    "                if not pred.eq(target.view_as(pred)):   ## If you just want so see the failing examples\n",
    "                    datacv = datacv.cpu()\n",
    "                    grid = utils.make_grid(datacv)\n",
    "                    grid = grid.numpy().transpose((1,2,0))\n",
    "                    #plt.imshow(grid)\n",
    "                    #cv_mat = data.cpu().data.squeeze().numpy()\n",
    "                    #cv_mat = cv2.resize(cv_mat, (128, 640))\n",
    "                    #plt.figure(figsize=(320,64))\n",
    "                    cv2.imshow(\"test image\", grid)\n",
    "                    #plt.axis('off')\n",
    "                    #plt.ioff()\n",
    "                    #plt.show()\n",
    "                    print(\"Target label is : %d\" % target.cpu().item())\n",
    "                    print(\"Predicted label is : %d\" % (pred.cpu().data.item()))\n",
    "                    cv2.waitKey()\n",
    "                 \n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= len(TestData.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(TestData.dataset),\n",
    "        100. * correct / len(TestData.dataset)))\n",
    "'''\n",
    "num_train_epochs = 40\n",
    "for epoch in range(1, num_train_epochs + 1):\n",
    "    train(epoch)\n",
    "'''\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.L1Loss()\n",
    "input1 = torch.tensor([-1.88],requires_grad=True,dtype=torch.float32)\n",
    "input2 = torch.tensor([-1.88],requires_grad=True,dtype=torch.float32)\n",
    "target = torch.tensor([1],dtype=torch.float64)\n",
    "b = input2.max(0, keepdim=True)[0]\n",
    "#output = loss(input1,input2)\n",
    "print(b)\n",
    "#output.backward()\n",
    "#print(output)\n",
    "print(input1.eq(input2).sum().item())\n",
    "\n",
    "#x = output.max(0,keepdim=True)[1]\n",
    "m = input2.view_as(0)\n",
    "print(\"m\")\n",
    "print(m)\n",
    "\n",
    "correct = output.eq(target.view_as(output)).sum().item()\n",
    "print(correct)\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "all = 0\n",
    "a = torch.tensor([0],dtype=torch.float64)\n",
    "for batch_idx, sample in enumerate(dataloader2):\n",
    "    sample = sample.to(device)\n",
    "    print(sample['steer'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This function trains the neural network for one epoch\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(dataloader):\n",
    "        # Move the input and target data on the GPU\n",
    "        sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "        sample['steer'] = sample['steer'].type('torch.FloatTensor')\n",
    "        \n",
    "        data, target = sample['image'].to(device), sample['steer'].to(device)  # .cuda() works too instead of .to(device)\n",
    "        #loss = nn.L1Loss()\n",
    "        # Zero out gradients from previous step\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #print(output.type())\n",
    "        #print(\"target\")\n",
    "        #print(target.type())\n",
    "        #output = output.squeeze()\n",
    "        #loss = F.nll_loss(output, target)\n",
    "        loss = F.smooth_l1_loss(output, target)\n",
    "        #loss = loss(output, target)\n",
    "        loss.backward()\n",
    "        # Adjusting the parameters according to the loss function\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(dataloader.dataset),\n",
    "                100. * batch_idx / len(dataloader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = torch.device(\"cpu\")\n",
    "# Definition of the network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)    # FYI: In the lecture I forgot to add the padding, thats why the feature size calculation was wrong\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv8_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(327680, 50)\n",
    "        self.fc2 = nn.Linear(50, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)),2)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8_drop(self.conv8(x)))\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = x.view(-1, 327680)   # Flatten data for fully connected layer. Input size is 28*28, we have 2 pooling layers so we pool the spatial size down to 7*7. With 20 feature maps as the output of the previous conv we have in total 7x7x20 = 980 features.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "        '''\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x),2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv4(x),2))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv8_drop(self.conv8(x)), 2))\n",
    "        x = x.view(-1, 327680)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "        '''\n",
    "# We create the network, shift it on the GPU and define a optimizer on its parameters\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This function trains the neural network for one epoch\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(dataloader):\n",
    "        # Move the input and target data on the GPU\n",
    "        sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "        sample['steer'] = sample['steer'].type('torch.FloatTensor')\n",
    "        \n",
    "        data, target = sample['image'].to(device), sample['steer'].to(device)  # .cuda() works too instead of .to(device)\n",
    "        #loss = nn.L1Loss()\n",
    "        # Zero out gradients from previous step\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #print(output.type())\n",
    "        #print(\"target\")\n",
    "        #print(target.type())\n",
    "        #output = output.squeeze()\n",
    "        #loss = F.nll_loss(output, target)\n",
    "        loss = F.smooth_l1_loss(output, target)\n",
    "        #loss = loss(output, target)\n",
    "        loss.backward()\n",
    "        # Adjusting the parameters according to the loss function\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(dataloader.dataset),\n",
    "                100. * batch_idx / len(dataloader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for sample in dataloader2:\n",
    "            # Move the input and target data on the GPU\n",
    "            sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "            sample['steer'] = sample['steer'].type('torch.FloatTensor')\n",
    "            #loss = nn.L1Loss()\n",
    "            data, target = sample['image'].to(device), sample['steer'].to(device)  # .cuda() works too instead of .to(device)\n",
    "            output = model(data)\n",
    "            #output = output.squeeze()\n",
    "            #print(output)\n",
    "            #test_loss += F.nll_loss(output, target).item()\n",
    "            test_loss += F.smooth_l1_loss(output, target, size_average=False).item() # sum up batch loss\n",
    "            #test_loss += loss(output, target).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            #print(pred)\n",
    "            print(target)\n",
    "            #pred = output # get the index of the max log-probability\n",
    "            '''\n",
    "            if not pred.eq(target.view_as(pred)):   ## If you just want so see the failing examples\n",
    "                cv_mat = data.cuda().data.squeeze().numpy()\n",
    "                cv_mat = cv2.resize(cv_mat, (400, 400))\n",
    "                cv2.imshow(\"test image\", cv_mat)\n",
    "                print(\"Target label is : %d\" % target.cuda().item())\n",
    "                print(\"Predicted label is : %d\" % (pred.cuda().data.item()))\n",
    "                cv2.waitKey()\n",
    "            '''\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= len(dataloader2.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(dataloader2.dataset),\n",
    "        100. * correct / len(dataloader2.dataset)))\n",
    "\n",
    "num_train_epochs = 2\n",
    "for epoch in range(1, num_train_epochs + 1):\n",
    "    train(epoch)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

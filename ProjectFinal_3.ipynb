{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch.nn.functional as F\n",
    "torch.set_printoptions(linewidth=120)\n",
    "\n",
    "import pickle as serializer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this function seperates the different commands in 4 different dictionaries\n",
    "# DataDict0 is for command0 'continue'\n",
    "# DataDict1 is for command1 'left'\n",
    "# DataDict2 is for command2 'forward'\n",
    "# DataDict3 is for command3 'right'\n",
    "\n",
    "# Coding of values\n",
    "# command: 0 --> conintue, 1 -->left, 2 --> forward, 3 --> right. \n",
    "# direction: 0 --> left, 1 --> forward, 2 --> right.\n",
    "#Steer: [0 --> -0.8] ,[1 --> -0.2],[2 --> 0],[3 --> 0.2],[4 --> 0.8].\n",
    "\n",
    "\n",
    "with open('dataset.txt', 'rb') as f:\n",
    "    dataset = serializer.load(f)\n",
    "    \n",
    "DataDictAll = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "DataDict0 = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "DataDict1 = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "DataDict2 = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "DataDict3 = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "[c0, c1, c2,c3, c4] = [0,0,0,0,0]\n",
    "keys = dataset.keys()\n",
    "for key in keys:\n",
    "    for label in dataset[key]:\n",
    "        #DataDict[\"image\"].append(label[0])\n",
    "        if label[3] == 'left':\n",
    "            label[3] = 0\n",
    "        if label[3] == 'right':\n",
    "            label[3] = 2\n",
    "        if label[3] == 'forward':\n",
    "            label[3] = 1\n",
    "\n",
    "        if label[1] == -0.8:\n",
    "            label[1] = 0\n",
    "            c0+=1\n",
    "        if label[1] == -0.2:\n",
    "            label[1] = 1\n",
    "            c1+=1\n",
    "        if label[1] == 0:\n",
    "            label[1] = 2\n",
    "            c2+=1\n",
    "        if label[1] == 0.2:\n",
    "            label[1] = 3\n",
    "            c3+=1\n",
    "        if label[1] == 0.8:\n",
    "            label[1] = 4\n",
    "            #if label[]c4 +=1\n",
    "        if key == 'left':\n",
    "            key = 1\n",
    "            label.append(key)\n",
    "            DataDict1[\"image\"].append(label[0])\n",
    "            DataDict1[\"steer\"].append(label[1])\n",
    "            DataDict1[\"throttle\"].append(label[2])\n",
    "            DataDict1[\"direction\"].append(label[3])\n",
    "            DataDict1[\"command\"].append(label[4])\n",
    "            \n",
    "        if key == 'right':\n",
    "            key = 3\n",
    "            \n",
    "            label.append(key)\n",
    "            DataDict3[\"image\"].append(label[0])\n",
    "            DataDict3[\"steer\"].append(label[1])\n",
    "            DataDict3[\"throttle\"].append(label[2])\n",
    "            DataDict3[\"direction\"].append(label[3])\n",
    "            DataDict3[\"command\"].append(label[4])\n",
    "            \n",
    "        if key == 'forward':\n",
    "            key = 2\n",
    "            \n",
    "            label.append(key)\n",
    "            DataDict2[\"image\"].append(label[0])\n",
    "            DataDict2[\"steer\"].append(label[1])\n",
    "            DataDict2[\"throttle\"].append(label[2])\n",
    "            DataDict2[\"direction\"].append(label[3])\n",
    "            DataDict2[\"command\"].append(label[4])\n",
    "            \n",
    "        if key == 'continue':\n",
    "            key = 0\n",
    "            \n",
    "            label.append(key)\n",
    "            DataDict0[\"image\"].append(label[0])\n",
    "            DataDict0[\"steer\"].append(label[1])\n",
    "            DataDict0[\"throttle\"].append(label[2])\n",
    "            DataDict0[\"direction\"].append(label[3])\n",
    "            DataDict0[\"command\"].append(label[4])\n",
    "    \n",
    "        gut = 'Bilder/'+ label[0]\n",
    "        if os.path.exists(gut):\n",
    "            if key == 1:\n",
    "                label.append(key)\n",
    "                DataDict1[\"image\"].append(label[0])\n",
    "                DataDict1[\"steer\"].append(label[1])\n",
    "                DataDict1[\"throttle\"].append(label[2])\n",
    "                DataDict1[\"direction\"].append(label[3])\n",
    "                DataDict1[\"command\"].append(label[4])\n",
    "            if key == 3:\n",
    "                label.append(key)\n",
    "                DataDict3[\"image\"].append(label[0])\n",
    "                DataDict3[\"steer\"].append(label[1])\n",
    "                DataDict3[\"throttle\"].append(label[2])\n",
    "                DataDict3[\"direction\"].append(label[3])\n",
    "                DataDict3[\"command\"].append(label[4])\n",
    "            if key == 2:\n",
    "                label.append(key)\n",
    "                DataDict2[\"image\"].append(label[0])\n",
    "                DataDict2[\"steer\"].append(label[1])\n",
    "                DataDict2[\"throttle\"].append(label[2])\n",
    "                DataDict2[\"direction\"].append(label[3])\n",
    "                DataDict2[\"command\"].append(label[4])\n",
    "            if key == 0:\n",
    "                label.append(key)\n",
    "                DataDict0[\"image\"].append(label[0])\n",
    "                DataDict0[\"steer\"].append(label[1])\n",
    "                DataDict0[\"throttle\"].append(label[2])\n",
    "                DataDict0[\"direction\"].append(label[3])\n",
    "                DataDict0[\"command\"].append(label[4])\n",
    "            label.append(key)\n",
    "            DataDictAll[\"image\"].append(label[0])\n",
    "            DataDictAll[\"steer\"].append(label[1])\n",
    "            DataDictAll[\"throttle\"].append(label[2])\n",
    "            DataDictAll[\"direction\"].append(label[3])\n",
    "            DataDictAll[\"command\"].append(label[4])\n",
    "            \n",
    "print([c0,c1,c2,c3,c4])\n",
    "print(DataDict0['steer'])\n",
    "\n",
    "with open('DataDictAll.txt', 'wb') as f:\n",
    "    serializer.dump(DataDictAll, f)\n",
    "\n",
    "with open('DataDict0.txt', 'wb') as f:\n",
    "    serializer.dump(DataDict0, f)\n",
    "\n",
    "with open('DataDict1.txt', 'wb') as f:\n",
    "    serializer.dump(DataDict1, f)\n",
    "\n",
    "with open('DataDict2.txt', 'wb') as f:\n",
    "    serializer.dump(DataDict2, f)\n",
    "\n",
    "with open('DataDict3.txt', 'wb') as f:\n",
    "    serializer.dump(DataDict3, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chose the DataSet you want to train the network on\n",
    "ChosenDataset = 'DataDictHot.txt'\n",
    "\n",
    "with open(ChosenDataset, 'rb') as f:\n",
    "    dataset = serializer.load(f)\n",
    "\n",
    "class AISProject(Dataset):\n",
    "    \"\"\" AIS Project dataset.\"\"\"\n",
    "    def __init__(self, dictionary, root_dir, transform = None):\n",
    "\n",
    "        self.dictionary = pd.DataFrame.from_dict(dictionary)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        print(len(dictionary))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dictionary)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.dictionary.iloc[idx,0])\n",
    "        image = io.imread(img_name)\n",
    "        #steer = torch.tensor(self.dictionary.iloc[idx,1],dtype=torch.float32, requires_grad=True)\n",
    "        steer = torch.tensor(self.dictionary.iloc[idx,1],dtype=torch.long)\n",
    "        speed = torch.tensor(self.dictionary.iloc[idx,2],dtype = torch.float32)\n",
    "        direction = torch.tensor(self.dictionary.iloc[idx,3],dtype = torch.long)\n",
    "        command = torch.tensor(self.dictionary.iloc[idx,4],dtype = torch.uint8)\n",
    "        sample = {'image':image, 'steer': steer, 'speed': speed,'direction':direction, 'command':command }\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, steer, speed, direction, command = sample['image'], sample['steer'], sample['speed'], sample['direction'], sample['command']\n",
    "        image = image.transpose((2,0,1))\n",
    "        return {'image': torch.from_numpy(image), \n",
    "                'steer': torch.tensor(steer),\n",
    "               'speed': torch.tensor(speed),\n",
    "               'direction':torch.tensor(direction),\n",
    "               'command':torch.tensor(command)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    \"\"\"Class to crop our data. (Modified RandomCrop, so that the crop isn't random anymore)\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        #new_h, new_w = output_size\n",
    "        new_h = 64\n",
    "        image = image[new_h:h, 0:w]\n",
    "        #show_image to test whether the pictures are cropped as we wish\n",
    "        #show_image(image)\n",
    "        sample['image'] = image\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure()\\nshow_image(io.imread(os.path.join('Bilder/',img_name)))\\nplt.show()\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_image(image):\n",
    "    plt.imshow(image)\n",
    "\n",
    "'''\n",
    "plt.figure()\n",
    "show_image(io.imread(os.path.join('Bilder/',img_name)))\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(transformed_dataset)):\\n    sample = transformed_dataset[i]\\n    \\n    print(i, sample)\\n    if i == 1:\\n        break\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_dataset = AISProject(dictionary = dataset, root_dir='Bilder/', \n",
    "                                transform = transforms.Compose([ToTensor()]))\n",
    "transformed_dataset2 = AISProject(dictionary = dataset, root_dir='Bilder/', \n",
    "                                transform = transforms.Compose([ToTensor()]))\n",
    "'''\n",
    "for i in range(len(transformed_dataset)):\n",
    "    sample = transformed_dataset[i]\n",
    "    \n",
    "    print(i, sample)\n",
    "    if i == 1:\n",
    "        break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef show_labels_batch(sample_batched):\\n    \"\"\"Show image with labels for a batch of samples.\"\"\"\\n    images_batch, labels_batch =         sample_batched[\\'image\\'], sample_batched[\\'steer\\']\\n    batch_size = len(images_batch)\\n    im_size = images_batch.size(2)\\n    \\n    grid = utils.make_grid(images_batch)\\n    plt.imshow(grid.numpy().transpose((1,2,0)))\\n\\n\\n\\nfor i_batch, sample_batched in enumerate(TrainData):\\n    print(i_batch, sample_batched[\\'image\\'].size(), \\n         sample_batched[\\'steer\\'].size())\\n\\n    if i_batch == 1:\\n        plt.figure(figsize=(40,40))\\n        show_labels_batch(sample_batched)\\n        plt.axis(\\'off\\')\\n        plt.ioff()\\n        plt.show()\\n        break\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData = DataLoader(transformed_dataset, batch_size=32, \n",
    "                        shuffle=True, pin_memory=False,num_workers = 0)\n",
    "TestData = DataLoader(transformed_dataset2, batch_size=1, \n",
    "                        shuffle=True, pin_memory=False)\n",
    "'''\n",
    "for batch_idx, dataset in enumerate(TrainData):\n",
    "    print(batch_idx)\n",
    "    print(dataset['image'].size())\n",
    "    print(dataset['command'].size())\n",
    "    print(dataset['direction'])\n",
    "    if batch_idx == 3:\n",
    "        break\n",
    "'''\n",
    "'''\n",
    "def show_labels_batch(sample_batched):\n",
    "    \"\"\"Show image with labels for a batch of samples.\"\"\"\n",
    "    images_batch, labels_batch = \\\n",
    "        sample_batched['image'], sample_batched['steer']\n",
    "    batch_size = len(images_batch)\n",
    "    im_size = images_batch.size(2)\n",
    "    \n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imshow(grid.numpy().transpose((1,2,0)))\n",
    "\n",
    "\n",
    "\n",
    "for i_batch, sample_batched in enumerate(TrainData):\n",
    "    print(i_batch, sample_batched['image'].size(), \n",
    "         sample_batched['steer'].size())\n",
    "\n",
    "    if i_batch == 1:\n",
    "        plt.figure(figsize=(40,40))\n",
    "        show_labels_batch(sample_batched)\n",
    "        plt.axis('off')\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "        break\n",
    "'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Network with branches '''\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "# Definition of the network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)    # FYI: In the lecture I forgot to add the padding, thats why the feature size calculation was wrong\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv8_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(81920, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        #here we start the branching\n",
    "        # Brach 0\n",
    "        self.fc1B0 = nn.Linear(512, 256)\n",
    "        self.fc2B0 = nn.Linear(256, 256)\n",
    "        self.fc3B0 = nn.Linear(256, 5) # the output is direction\n",
    "        \n",
    "        #ToDo: implement other branches\n",
    "        \n",
    "        # Brach 1\n",
    "        self.fc1B1 = nn.Linear(512, 256)\n",
    "        self.fc2B1 = nn.Linear(256, 256)\n",
    "        self.fc3B1 = nn.Linear(256, 5) # the output is direction\n",
    "        # Brach 2\n",
    "        self.fc1B2 = nn.Linear(512, 256)\n",
    "        self.fc2B2 = nn.Linear(256, 256)\n",
    "        self.fc3B2 = nn.Linear(256, 5) # the output is direction\n",
    "        # Brach 3\n",
    "        self.fc1B3 = nn.Linear(512, 256)\n",
    "        self.fc2B3 = nn.Linear(256, 256)\n",
    "        self.fc3B3 = nn.Linear(256, 5) # the output is directiontput is direction\n",
    "        \n",
    "\n",
    "    def forward(self, x, command):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)),2)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8_drop(self.conv8(x)))\n",
    "        x = F.max_pool2d(x,4)\n",
    "        x = x.view(-1, 81920)   # Flatten data for fully connected layer. Input size is 28*28, we have 2 pooling layers so we pool the spatial size down to 7*7. With 20 feature maps as the output of the previous conv we have in total 7x7x20 = 980 features.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        # choosing the branch\n",
    "        out = []\n",
    "        y = None\n",
    "        for Idx in range(0,1):\n",
    "            if command[Idx].item() == 0:\n",
    "                x0 = F.relu(self.fc1B0(x))\n",
    "                x0 = F.relu(self.fc2B0(x0))\n",
    "                x0 = F.dropout(x0, training=self.training)\n",
    "                x0 = self.fc3B0(x0)\n",
    "                #print(\"0\")\n",
    "                o0 = F.log_softmax(x0, dim=1)\n",
    "                return o0\n",
    "            #out.append(o0.unsqueeze(0))\n",
    "            elif command[Idx].item() == 1:\n",
    "                x1 = F.relu(self.fc1B1(x))\n",
    "                x1 = F.relu(self.fc2B1(x1))\n",
    "                x1 = F.dropout(x1, training=self.training)\n",
    "                x1 = self.fc3B1(x1)\n",
    "                #print(\"1\")\n",
    "                o1 = F.log_softmax(x1, dim=1)\n",
    "                return o1\n",
    "                #out.append(o1.unsqueeze(0))\n",
    "            elif command[Idx].item() == 2:\n",
    "                x2 = F.relu(self.fc1B2(x))\n",
    "                x2 = F.relu(self.fc2B2(x2))\n",
    "                x2 = F.dropout(x2, training=self.training)\n",
    "                x2 = self.fc3B2(x2)\n",
    "                #print(\"2\")\n",
    "                o2 = F.log_softmax(x2, dim=1)\n",
    "                return o2\n",
    "                #out.append(o2.unsqueeze(0))\n",
    "            elif command[Idx].item() == 3:\n",
    "                x3 = F.relu(self.fc1B3(x))\n",
    "                x3 = F.relu(self.fc2B3(x3))\n",
    "                x3 = F.dropout(x3, training=self.training)\n",
    "                x3 = self.fc3B3(x3)\n",
    "                #print(\"3\")\n",
    "                o3 = F.log_softmax(x3, dim=1)\n",
    "                return o3\n",
    "                #out.append(o3.unsqueeze(0))\n",
    "        #return out\n",
    "        \n",
    "        '''\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x),2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv4(x),2))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv8_drop(self.conv8(x)), 2))\n",
    "        x = x.view(-1, 81920)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "        '''\n",
    "\n",
    "# We create the network, shift it on the GPU and define a optimizer on its parameters\n",
    "#model1 = Net().to(device)\n",
    "#torch.save(model1, \"Netz2.pt\")\n",
    "model = torch.load(\"Netz2.pt\")\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function trains the neural network for one epoch\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(TrainData):\n",
    "        #print(batch_idx)\n",
    "        # Move the input and target data on the GPU\n",
    "        sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "\n",
    "        data, target = sample['image'].to(device), sample['steer'].to(device)  # .cuda() works too instead of .to(device)\n",
    "        command = sample['command']\n",
    "        if True:\n",
    "            out = []\n",
    "            # Zero out gradients from previous step\n",
    "            optimizer.zero_grad()\n",
    "            for i in range(0,len(command)):\n",
    "                output = model(data[i].unsqueeze(0), command[i])\n",
    "                out.append(output)\n",
    "            output = torch.cat(out)\n",
    "            #output = model(data, command)\n",
    "            #print(output.size())\n",
    "            #print(target.size())\n",
    "            #output = model(i, j)\n",
    "            #for i in output:\n",
    "                #print(output)\n",
    "                #output = torch.cat(output)\n",
    "            #print(output.size())\n",
    "            #print(output.shape())\n",
    "            \n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            # Adjusting the parameters according to the loss function\n",
    "            optimizer.step()\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(TrainData.dataset),\n",
    "                    100. * batch_idx / len(TrainData), loss.item()))\n",
    "    torch.save(model, \"Netz2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/9901 (0%)]\tLoss: 1.827163\n",
      "Train Epoch: 1 [320/9901 (3%)]\tLoss: 1.113026\n",
      "Train Epoch: 1 [640/9901 (6%)]\tLoss: 0.479066\n",
      "Train Epoch: 1 [960/9901 (10%)]\tLoss: 0.686203\n",
      "Train Epoch: 1 [1280/9901 (13%)]\tLoss: 0.692143\n",
      "Train Epoch: 1 [1600/9901 (16%)]\tLoss: 0.393614\n",
      "Train Epoch: 1 [1920/9901 (19%)]\tLoss: 0.272511\n",
      "Train Epoch: 1 [2240/9901 (23%)]\tLoss: 0.651722\n",
      "Train Epoch: 1 [2560/9901 (26%)]\tLoss: 0.227900\n",
      "Train Epoch: 1 [2880/9901 (29%)]\tLoss: 0.705589\n",
      "Train Epoch: 1 [3200/9901 (32%)]\tLoss: 0.274385\n",
      "Train Epoch: 1 [3520/9901 (35%)]\tLoss: 0.655247\n",
      "Train Epoch: 1 [3840/9901 (39%)]\tLoss: 0.298184\n",
      "Train Epoch: 1 [4160/9901 (42%)]\tLoss: 0.305130\n",
      "Train Epoch: 1 [4480/9901 (45%)]\tLoss: 0.202750\n",
      "Train Epoch: 1 [4800/9901 (48%)]\tLoss: 0.061066\n",
      "Train Epoch: 1 [5120/9901 (52%)]\tLoss: 0.625941\n",
      "Train Epoch: 1 [5440/9901 (55%)]\tLoss: 0.126765\n",
      "Train Epoch: 1 [5760/9901 (58%)]\tLoss: 0.202482\n",
      "Train Epoch: 1 [6080/9901 (61%)]\tLoss: 0.204182\n",
      "Train Epoch: 1 [6400/9901 (65%)]\tLoss: 0.253248\n",
      "Train Epoch: 1 [6720/9901 (68%)]\tLoss: 0.117058\n",
      "Train Epoch: 1 [7040/9901 (71%)]\tLoss: 0.107717\n",
      "Train Epoch: 1 [7360/9901 (74%)]\tLoss: 0.145390\n",
      "Train Epoch: 1 [7680/9901 (77%)]\tLoss: 0.129987\n",
      "Train Epoch: 1 [8000/9901 (81%)]\tLoss: 0.165140\n",
      "Train Epoch: 1 [8320/9901 (84%)]\tLoss: 0.034264\n",
      "Train Epoch: 1 [8640/9901 (87%)]\tLoss: 0.152051\n",
      "Train Epoch: 1 [8960/9901 (90%)]\tLoss: 0.278936\n",
      "Train Epoch: 1 [9280/9901 (94%)]\tLoss: 0.300583\n",
      "Train Epoch: 1 [9600/9901 (97%)]\tLoss: 0.120701\n",
      "Train Epoch: 2 [0/9901 (0%)]\tLoss: 0.096850\n",
      "Train Epoch: 2 [320/9901 (3%)]\tLoss: 0.037386\n",
      "Train Epoch: 2 [640/9901 (6%)]\tLoss: 0.034639\n",
      "Train Epoch: 2 [960/9901 (10%)]\tLoss: 0.200159\n",
      "Train Epoch: 2 [1280/9901 (13%)]\tLoss: 0.178670\n",
      "Train Epoch: 2 [1600/9901 (16%)]\tLoss: 0.061634\n",
      "Train Epoch: 2 [1920/9901 (19%)]\tLoss: 0.038558\n",
      "Train Epoch: 2 [2240/9901 (23%)]\tLoss: 0.115124\n",
      "Train Epoch: 2 [2560/9901 (26%)]\tLoss: 0.073628\n",
      "Train Epoch: 2 [2880/9901 (29%)]\tLoss: 0.024911\n",
      "Train Epoch: 2 [3200/9901 (32%)]\tLoss: 0.107745\n",
      "Train Epoch: 2 [3520/9901 (35%)]\tLoss: 0.039312\n",
      "Train Epoch: 2 [3840/9901 (39%)]\tLoss: 0.021880\n",
      "Train Epoch: 2 [4160/9901 (42%)]\tLoss: 0.055190\n",
      "Train Epoch: 2 [4480/9901 (45%)]\tLoss: 0.114834\n",
      "Train Epoch: 2 [4800/9901 (48%)]\tLoss: 0.172117\n",
      "Train Epoch: 2 [5120/9901 (52%)]\tLoss: 0.057324\n",
      "Train Epoch: 2 [5440/9901 (55%)]\tLoss: 0.049882\n",
      "Train Epoch: 2 [5760/9901 (58%)]\tLoss: 0.040623\n",
      "Train Epoch: 2 [6080/9901 (61%)]\tLoss: 0.081117\n",
      "Train Epoch: 2 [6400/9901 (65%)]\tLoss: 0.043264\n",
      "Train Epoch: 2 [6720/9901 (68%)]\tLoss: 0.191631\n",
      "Train Epoch: 2 [7040/9901 (71%)]\tLoss: 0.159844\n",
      "Train Epoch: 2 [7360/9901 (74%)]\tLoss: 0.006317\n",
      "Train Epoch: 2 [7680/9901 (77%)]\tLoss: 0.068102\n",
      "Train Epoch: 2 [8000/9901 (81%)]\tLoss: 0.010366\n",
      "Train Epoch: 2 [8320/9901 (84%)]\tLoss: 0.065405\n",
      "Train Epoch: 2 [8640/9901 (87%)]\tLoss: 0.009784\n",
      "Train Epoch: 2 [8960/9901 (90%)]\tLoss: 0.217647\n",
      "Train Epoch: 2 [9280/9901 (94%)]\tLoss: 0.165203\n",
      "Train Epoch: 2 [9600/9901 (97%)]\tLoss: 0.107399\n",
      "Train Epoch: 3 [0/9901 (0%)]\tLoss: 0.148094\n",
      "Train Epoch: 3 [320/9901 (3%)]\tLoss: 0.025475\n",
      "Train Epoch: 3 [640/9901 (6%)]\tLoss: 0.095439\n",
      "Train Epoch: 3 [960/9901 (10%)]\tLoss: 0.075288\n",
      "Train Epoch: 3 [1280/9901 (13%)]\tLoss: 0.151060\n",
      "Train Epoch: 3 [1600/9901 (16%)]\tLoss: 0.090808\n",
      "Train Epoch: 3 [1920/9901 (19%)]\tLoss: 0.044502\n",
      "Train Epoch: 3 [2240/9901 (23%)]\tLoss: 0.051383\n",
      "Train Epoch: 3 [2560/9901 (26%)]\tLoss: 0.065843\n",
      "Train Epoch: 3 [2880/9901 (29%)]\tLoss: 0.010194\n",
      "Train Epoch: 3 [3200/9901 (32%)]\tLoss: 0.025874\n",
      "Train Epoch: 3 [3520/9901 (35%)]\tLoss: 0.018426\n",
      "Train Epoch: 3 [3840/9901 (39%)]\tLoss: 0.032015\n",
      "Train Epoch: 3 [4160/9901 (42%)]\tLoss: 0.428813\n",
      "Train Epoch: 3 [4480/9901 (45%)]\tLoss: 0.013681\n",
      "Train Epoch: 3 [4800/9901 (48%)]\tLoss: 0.124523\n",
      "Train Epoch: 3 [5120/9901 (52%)]\tLoss: 0.025288\n",
      "Train Epoch: 3 [5440/9901 (55%)]\tLoss: 0.067910\n",
      "Train Epoch: 3 [5760/9901 (58%)]\tLoss: 0.143960\n",
      "Train Epoch: 3 [6080/9901 (61%)]\tLoss: 0.005030\n",
      "Train Epoch: 3 [6400/9901 (65%)]\tLoss: 0.208505\n",
      "Train Epoch: 3 [6720/9901 (68%)]\tLoss: 0.067257\n",
      "Train Epoch: 3 [7040/9901 (71%)]\tLoss: 0.235441\n",
      "Train Epoch: 3 [7360/9901 (74%)]\tLoss: 0.014088\n",
      "Train Epoch: 3 [7680/9901 (77%)]\tLoss: 0.024155\n",
      "Train Epoch: 3 [8000/9901 (81%)]\tLoss: 0.056536\n",
      "Train Epoch: 3 [8320/9901 (84%)]\tLoss: 0.217111\n",
      "Train Epoch: 3 [8640/9901 (87%)]\tLoss: 0.109418\n",
      "Train Epoch: 3 [8960/9901 (90%)]\tLoss: 0.094605\n",
      "Train Epoch: 3 [9280/9901 (94%)]\tLoss: 0.008124\n",
      "Train Epoch: 3 [9600/9901 (97%)]\tLoss: 0.078020\n",
      "Train Epoch: 4 [0/9901 (0%)]\tLoss: 0.146803\n",
      "Train Epoch: 4 [320/9901 (3%)]\tLoss: 0.101315\n",
      "Train Epoch: 4 [640/9901 (6%)]\tLoss: 0.013494\n",
      "Train Epoch: 4 [960/9901 (10%)]\tLoss: 0.067428\n",
      "Train Epoch: 4 [1280/9901 (13%)]\tLoss: 0.055773\n",
      "Train Epoch: 4 [1600/9901 (16%)]\tLoss: 0.057556\n",
      "Train Epoch: 4 [1920/9901 (19%)]\tLoss: 0.208350\n",
      "Train Epoch: 4 [2240/9901 (23%)]\tLoss: 0.175653\n",
      "Train Epoch: 4 [2560/9901 (26%)]\tLoss: 0.254225\n",
      "Train Epoch: 4 [2880/9901 (29%)]\tLoss: 0.054613\n",
      "Train Epoch: 4 [3200/9901 (32%)]\tLoss: 0.279485\n",
      "Train Epoch: 4 [3520/9901 (35%)]\tLoss: 0.090223\n",
      "Train Epoch: 4 [3840/9901 (39%)]\tLoss: 0.048193\n",
      "Train Epoch: 4 [4160/9901 (42%)]\tLoss: 0.091765\n",
      "Train Epoch: 4 [4480/9901 (45%)]\tLoss: 0.001176\n",
      "Train Epoch: 4 [4800/9901 (48%)]\tLoss: 0.089836\n",
      "Train Epoch: 4 [5120/9901 (52%)]\tLoss: 0.035777\n",
      "Train Epoch: 4 [5440/9901 (55%)]\tLoss: 0.724518\n",
      "Train Epoch: 4 [5760/9901 (58%)]\tLoss: 0.056890\n",
      "Train Epoch: 4 [6080/9901 (61%)]\tLoss: 0.034984\n",
      "Train Epoch: 4 [6400/9901 (65%)]\tLoss: 0.072396\n",
      "Train Epoch: 4 [6720/9901 (68%)]\tLoss: 0.029671\n",
      "Train Epoch: 4 [7040/9901 (71%)]\tLoss: 0.034315\n",
      "Train Epoch: 4 [7360/9901 (74%)]\tLoss: 0.017569\n",
      "Train Epoch: 4 [7680/9901 (77%)]\tLoss: 0.022831\n",
      "Train Epoch: 4 [8000/9901 (81%)]\tLoss: 0.023740\n",
      "Train Epoch: 4 [8320/9901 (84%)]\tLoss: 0.057287\n",
      "Train Epoch: 4 [8640/9901 (87%)]\tLoss: 0.012161\n",
      "Train Epoch: 4 [8960/9901 (90%)]\tLoss: 0.144676\n",
      "Train Epoch: 4 [9280/9901 (94%)]\tLoss: 0.061161\n",
      "Train Epoch: 4 [9600/9901 (97%)]\tLoss: 0.054289\n",
      "Train Epoch: 5 [0/9901 (0%)]\tLoss: 0.142387\n",
      "Train Epoch: 5 [320/9901 (3%)]\tLoss: 0.011492\n",
      "Train Epoch: 5 [640/9901 (6%)]\tLoss: 0.024345\n",
      "Train Epoch: 5 [960/9901 (10%)]\tLoss: 0.037314\n",
      "Train Epoch: 5 [1280/9901 (13%)]\tLoss: 0.016015\n",
      "Train Epoch: 5 [1600/9901 (16%)]\tLoss: 0.001348\n",
      "Train Epoch: 5 [1920/9901 (19%)]\tLoss: 0.029844\n",
      "Train Epoch: 5 [2240/9901 (23%)]\tLoss: 0.016119\n",
      "Train Epoch: 5 [2560/9901 (26%)]\tLoss: 0.020649\n",
      "Train Epoch: 5 [2880/9901 (29%)]\tLoss: 0.020424\n",
      "Train Epoch: 5 [3200/9901 (32%)]\tLoss: 0.132108\n",
      "Train Epoch: 5 [3520/9901 (35%)]\tLoss: 0.003598\n",
      "Train Epoch: 5 [3840/9901 (39%)]\tLoss: 0.148790\n",
      "Train Epoch: 5 [4160/9901 (42%)]\tLoss: 0.109263\n",
      "Train Epoch: 5 [4480/9901 (45%)]\tLoss: 0.012286\n",
      "Train Epoch: 5 [4800/9901 (48%)]\tLoss: 0.009016\n",
      "Train Epoch: 5 [5120/9901 (52%)]\tLoss: 0.113292\n",
      "Train Epoch: 5 [5440/9901 (55%)]\tLoss: 0.095904\n",
      "Train Epoch: 5 [5760/9901 (58%)]\tLoss: 0.028587\n",
      "Train Epoch: 5 [6080/9901 (61%)]\tLoss: 0.003237\n",
      "Train Epoch: 5 [6400/9901 (65%)]\tLoss: 0.033753\n",
      "Train Epoch: 5 [6720/9901 (68%)]\tLoss: 0.093075\n",
      "Train Epoch: 5 [7040/9901 (71%)]\tLoss: 0.001857\n",
      "Train Epoch: 5 [7360/9901 (74%)]\tLoss: 0.027479\n",
      "Train Epoch: 5 [7680/9901 (77%)]\tLoss: 0.008709\n",
      "Train Epoch: 5 [8000/9901 (81%)]\tLoss: 0.004112\n",
      "Train Epoch: 5 [8320/9901 (84%)]\tLoss: 0.013347\n",
      "Train Epoch: 5 [8640/9901 (87%)]\tLoss: 0.112527\n",
      "Train Epoch: 5 [8960/9901 (90%)]\tLoss: 0.032256\n",
      "Train Epoch: 5 [9280/9901 (94%)]\tLoss: 0.058439\n",
      "Train Epoch: 5 [9600/9901 (97%)]\tLoss: 0.084275\n",
      "Train Epoch: 6 [0/9901 (0%)]\tLoss: 0.108769\n",
      "Train Epoch: 6 [320/9901 (3%)]\tLoss: 0.011570\n",
      "Train Epoch: 6 [640/9901 (6%)]\tLoss: 0.008610\n",
      "Train Epoch: 6 [960/9901 (10%)]\tLoss: 0.026811\n",
      "Train Epoch: 6 [1280/9901 (13%)]\tLoss: 0.001734\n",
      "Train Epoch: 6 [1600/9901 (16%)]\tLoss: 0.007886\n",
      "Train Epoch: 6 [1920/9901 (19%)]\tLoss: 0.077606\n",
      "Train Epoch: 6 [2240/9901 (23%)]\tLoss: 0.049938\n",
      "Train Epoch: 6 [2560/9901 (26%)]\tLoss: 0.013794\n",
      "Train Epoch: 6 [2880/9901 (29%)]\tLoss: 0.001739\n",
      "Train Epoch: 6 [3200/9901 (32%)]\tLoss: 0.039282\n",
      "Train Epoch: 6 [3520/9901 (35%)]\tLoss: 0.001986\n",
      "Train Epoch: 6 [3840/9901 (39%)]\tLoss: 0.025573\n",
      "Train Epoch: 6 [4160/9901 (42%)]\tLoss: 0.028792\n",
      "Train Epoch: 6 [4480/9901 (45%)]\tLoss: 0.008420\n",
      "Train Epoch: 6 [4800/9901 (48%)]\tLoss: 0.002392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 6 [5120/9901 (52%)]\tLoss: 0.007587\n",
      "Train Epoch: 6 [5440/9901 (55%)]\tLoss: 0.002273\n",
      "Train Epoch: 6 [5760/9901 (58%)]\tLoss: 0.003994\n",
      "Train Epoch: 6 [6080/9901 (61%)]\tLoss: 0.014513\n",
      "Train Epoch: 6 [6400/9901 (65%)]\tLoss: 0.022926\n",
      "Train Epoch: 6 [6720/9901 (68%)]\tLoss: 0.034561\n",
      "Train Epoch: 6 [7040/9901 (71%)]\tLoss: 0.126454\n",
      "Train Epoch: 6 [7360/9901 (74%)]\tLoss: 0.006377\n",
      "Train Epoch: 6 [7680/9901 (77%)]\tLoss: 0.006366\n",
      "Train Epoch: 6 [8000/9901 (81%)]\tLoss: 0.001688\n",
      "Train Epoch: 6 [8320/9901 (84%)]\tLoss: 0.052434\n",
      "Train Epoch: 6 [8640/9901 (87%)]\tLoss: 0.367833\n",
      "Train Epoch: 6 [8960/9901 (90%)]\tLoss: 0.006979\n",
      "Train Epoch: 6 [9280/9901 (94%)]\tLoss: 0.049295\n",
      "Train Epoch: 6 [9600/9901 (97%)]\tLoss: 0.046822\n",
      "Train Epoch: 7 [0/9901 (0%)]\tLoss: 0.023692\n",
      "Train Epoch: 7 [320/9901 (3%)]\tLoss: 0.009103\n",
      "Train Epoch: 7 [640/9901 (6%)]\tLoss: 0.009635\n",
      "Train Epoch: 7 [960/9901 (10%)]\tLoss: 0.002167\n",
      "Train Epoch: 7 [1280/9901 (13%)]\tLoss: 0.008651\n",
      "Train Epoch: 7 [1600/9901 (16%)]\tLoss: 0.034448\n",
      "Train Epoch: 7 [1920/9901 (19%)]\tLoss: 0.031344\n",
      "Train Epoch: 7 [2240/9901 (23%)]\tLoss: 0.057495\n",
      "Train Epoch: 7 [2560/9901 (26%)]\tLoss: 0.007054\n",
      "Train Epoch: 7 [2880/9901 (29%)]\tLoss: 0.007248\n",
      "Train Epoch: 7 [3200/9901 (32%)]\tLoss: 0.000892\n",
      "Train Epoch: 7 [3520/9901 (35%)]\tLoss: 0.002218\n",
      "Train Epoch: 7 [3840/9901 (39%)]\tLoss: 0.150204\n",
      "Train Epoch: 7 [4160/9901 (42%)]\tLoss: 0.023970\n",
      "Train Epoch: 7 [4480/9901 (45%)]\tLoss: 0.008420\n",
      "Train Epoch: 7 [4800/9901 (48%)]\tLoss: 0.003843\n",
      "Train Epoch: 7 [5120/9901 (52%)]\tLoss: 0.003612\n",
      "Train Epoch: 7 [5440/9901 (55%)]\tLoss: 0.004725\n",
      "Train Epoch: 7 [5760/9901 (58%)]\tLoss: 0.002960\n",
      "Train Epoch: 7 [6080/9901 (61%)]\tLoss: 0.003962\n",
      "Train Epoch: 7 [6400/9901 (65%)]\tLoss: 0.001101\n",
      "Train Epoch: 7 [6720/9901 (68%)]\tLoss: 0.009882\n",
      "Train Epoch: 7 [7040/9901 (71%)]\tLoss: 0.148080\n",
      "Train Epoch: 7 [7360/9901 (74%)]\tLoss: 0.072787\n",
      "Train Epoch: 7 [7680/9901 (77%)]\tLoss: 0.001340\n",
      "Train Epoch: 7 [8000/9901 (81%)]\tLoss: 0.209355\n",
      "Train Epoch: 7 [8320/9901 (84%)]\tLoss: 0.041616\n",
      "Train Epoch: 7 [8640/9901 (87%)]\tLoss: 0.057633\n",
      "Train Epoch: 7 [8960/9901 (90%)]\tLoss: 0.072807\n",
      "Train Epoch: 7 [9280/9901 (94%)]\tLoss: 0.038186\n",
      "Train Epoch: 7 [9600/9901 (97%)]\tLoss: 0.009745\n",
      "Train Epoch: 8 [0/9901 (0%)]\tLoss: 0.081426\n",
      "Train Epoch: 8 [320/9901 (3%)]\tLoss: 0.001782\n",
      "Train Epoch: 8 [640/9901 (6%)]\tLoss: 0.004567\n",
      "Train Epoch: 8 [960/9901 (10%)]\tLoss: 0.211617\n",
      "Train Epoch: 8 [1280/9901 (13%)]\tLoss: 0.004832\n",
      "Train Epoch: 8 [1600/9901 (16%)]\tLoss: 0.002000\n",
      "Train Epoch: 8 [1920/9901 (19%)]\tLoss: 0.004746\n",
      "Train Epoch: 8 [2240/9901 (23%)]\tLoss: 0.066814\n",
      "Train Epoch: 8 [2560/9901 (26%)]\tLoss: 0.000331\n",
      "Train Epoch: 8 [2880/9901 (29%)]\tLoss: 0.004988\n",
      "Train Epoch: 8 [3200/9901 (32%)]\tLoss: 0.005058\n",
      "Train Epoch: 8 [3520/9901 (35%)]\tLoss: 0.000890\n",
      "Train Epoch: 8 [3840/9901 (39%)]\tLoss: 0.037493\n",
      "Train Epoch: 8 [4160/9901 (42%)]\tLoss: 0.188277\n",
      "Train Epoch: 8 [4480/9901 (45%)]\tLoss: 0.003408\n",
      "Train Epoch: 8 [4800/9901 (48%)]\tLoss: 0.010213\n",
      "Train Epoch: 8 [5120/9901 (52%)]\tLoss: 0.012290\n",
      "Train Epoch: 8 [5440/9901 (55%)]\tLoss: 0.017594\n",
      "Train Epoch: 8 [5760/9901 (58%)]\tLoss: 0.006663\n",
      "Train Epoch: 8 [6080/9901 (61%)]\tLoss: 0.014778\n",
      "Train Epoch: 8 [6400/9901 (65%)]\tLoss: 0.001664\n",
      "Train Epoch: 8 [6720/9901 (68%)]\tLoss: 0.000816\n",
      "Train Epoch: 8 [7040/9901 (71%)]\tLoss: 0.006517\n",
      "Train Epoch: 8 [7360/9901 (74%)]\tLoss: 0.034671\n",
      "Train Epoch: 8 [7680/9901 (77%)]\tLoss: 0.038535\n",
      "Train Epoch: 8 [8000/9901 (81%)]\tLoss: 0.120567\n",
      "Train Epoch: 8 [8320/9901 (84%)]\tLoss: 0.082493\n",
      "Train Epoch: 8 [8640/9901 (87%)]\tLoss: 0.007572\n",
      "Train Epoch: 8 [8960/9901 (90%)]\tLoss: 0.003741\n",
      "Train Epoch: 8 [9280/9901 (94%)]\tLoss: 0.001947\n",
      "Train Epoch: 8 [9600/9901 (97%)]\tLoss: 0.000316\n",
      "Train Epoch: 9 [0/9901 (0%)]\tLoss: 0.007494\n",
      "Train Epoch: 9 [320/9901 (3%)]\tLoss: 0.001683\n",
      "Train Epoch: 9 [640/9901 (6%)]\tLoss: 0.041571\n",
      "Train Epoch: 9 [960/9901 (10%)]\tLoss: 0.004380\n",
      "Train Epoch: 9 [1280/9901 (13%)]\tLoss: 0.004469\n",
      "Train Epoch: 9 [1600/9901 (16%)]\tLoss: 0.004653\n",
      "Train Epoch: 9 [1920/9901 (19%)]\tLoss: 0.002502\n",
      "Train Epoch: 9 [2240/9901 (23%)]\tLoss: 0.003367\n",
      "Train Epoch: 9 [2560/9901 (26%)]\tLoss: 0.002728\n",
      "Train Epoch: 9 [2880/9901 (29%)]\tLoss: 0.002131\n",
      "Train Epoch: 9 [3200/9901 (32%)]\tLoss: 0.002215\n",
      "Train Epoch: 9 [3520/9901 (35%)]\tLoss: 0.003628\n",
      "Train Epoch: 9 [3840/9901 (39%)]\tLoss: 0.027332\n",
      "Train Epoch: 9 [4160/9901 (42%)]\tLoss: 0.004280\n",
      "Train Epoch: 9 [4480/9901 (45%)]\tLoss: 0.000847\n",
      "Train Epoch: 9 [4800/9901 (48%)]\tLoss: 0.005639\n",
      "Train Epoch: 9 [5120/9901 (52%)]\tLoss: 0.017710\n",
      "Train Epoch: 9 [5440/9901 (55%)]\tLoss: 0.004196\n",
      "Train Epoch: 9 [5760/9901 (58%)]\tLoss: 0.000480\n",
      "Train Epoch: 9 [6080/9901 (61%)]\tLoss: 0.000637\n",
      "Train Epoch: 9 [6400/9901 (65%)]\tLoss: 0.000979\n",
      "Train Epoch: 9 [6720/9901 (68%)]\tLoss: 0.004980\n",
      "Train Epoch: 9 [7040/9901 (71%)]\tLoss: 0.111070\n",
      "Train Epoch: 9 [7360/9901 (74%)]\tLoss: 0.092552\n",
      "Train Epoch: 9 [7680/9901 (77%)]\tLoss: 0.007952\n",
      "Train Epoch: 9 [8000/9901 (81%)]\tLoss: 0.002544\n",
      "Train Epoch: 9 [8320/9901 (84%)]\tLoss: 0.006984\n",
      "Train Epoch: 9 [8640/9901 (87%)]\tLoss: 0.011210\n",
      "Train Epoch: 9 [8960/9901 (90%)]\tLoss: 0.002652\n",
      "Train Epoch: 9 [9280/9901 (94%)]\tLoss: 0.019943\n",
      "Train Epoch: 9 [9600/9901 (97%)]\tLoss: 0.008875\n",
      "Train Epoch: 10 [0/9901 (0%)]\tLoss: 0.001636\n",
      "Train Epoch: 10 [320/9901 (3%)]\tLoss: 0.016565\n",
      "Train Epoch: 10 [640/9901 (6%)]\tLoss: 0.170965\n",
      "Train Epoch: 10 [960/9901 (10%)]\tLoss: 0.002552\n",
      "Train Epoch: 10 [1280/9901 (13%)]\tLoss: 0.021475\n",
      "Train Epoch: 10 [1600/9901 (16%)]\tLoss: 0.000253\n",
      "Train Epoch: 10 [1920/9901 (19%)]\tLoss: 0.004159\n",
      "Train Epoch: 10 [2240/9901 (23%)]\tLoss: 0.000908\n",
      "Train Epoch: 10 [2560/9901 (26%)]\tLoss: 0.000189\n",
      "Train Epoch: 10 [2880/9901 (29%)]\tLoss: 0.001643\n",
      "Train Epoch: 10 [3200/9901 (32%)]\tLoss: 0.006708\n",
      "Train Epoch: 10 [3520/9901 (35%)]\tLoss: 0.034820\n",
      "Train Epoch: 10 [3840/9901 (39%)]\tLoss: 0.003766\n",
      "Train Epoch: 10 [4160/9901 (42%)]\tLoss: 0.008877\n",
      "Train Epoch: 10 [4480/9901 (45%)]\tLoss: 0.013773\n",
      "Train Epoch: 10 [4800/9901 (48%)]\tLoss: 0.001695\n",
      "Train Epoch: 10 [5120/9901 (52%)]\tLoss: 0.026290\n",
      "Train Epoch: 10 [5440/9901 (55%)]\tLoss: 0.006220\n",
      "Train Epoch: 10 [5760/9901 (58%)]\tLoss: 0.219123\n",
      "Train Epoch: 10 [6080/9901 (61%)]\tLoss: 0.274048\n",
      "Train Epoch: 10 [6400/9901 (65%)]\tLoss: 0.061564\n",
      "Train Epoch: 10 [6720/9901 (68%)]\tLoss: 0.024514\n",
      "Train Epoch: 10 [7040/9901 (71%)]\tLoss: 0.001203\n",
      "Train Epoch: 10 [7360/9901 (74%)]\tLoss: 0.029568\n",
      "Train Epoch: 10 [7680/9901 (77%)]\tLoss: 0.008363\n",
      "Train Epoch: 10 [8000/9901 (81%)]\tLoss: 0.000705\n",
      "Train Epoch: 10 [8320/9901 (84%)]\tLoss: 0.023819\n",
      "Train Epoch: 10 [8640/9901 (87%)]\tLoss: 0.008692\n",
      "Train Epoch: 10 [8960/9901 (90%)]\tLoss: 0.003352\n",
      "Train Epoch: 10 [9280/9901 (94%)]\tLoss: 0.074516\n",
      "Train Epoch: 10 [9600/9901 (97%)]\tLoss: 0.038964\n",
      "\n",
      "Test set: Average loss: 0.0090, Accuracy: 9874/9901 (100%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def test():\n",
    "    #if os.path.isfile(\"Netz.pt\"):\n",
    "        #model = torch.load(\"Netz.pt\")\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for sample in TestData:\n",
    "            datacv = sample['image']\n",
    "            # Move the input and target data on the GPU\n",
    "            sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "            \n",
    "            #sample['direction'] = sample['direction'].type('torch.FloatTensor')\n",
    "            data, target = sample['image'].to(device), sample['steer'].to(device)  # .cuda() works too instead of .to(device)\n",
    "            command = sample['command']\n",
    "            if True:\n",
    "                output = model(data, command)\n",
    "                test_loss += F.nll_loss(output, target).item()\n",
    "                pred = output.max(1, keepdim=True)[1]\n",
    "                #pred = output # get the index of the max log-probability\n",
    "                '''\n",
    "                if not pred.eq(target.view_as(pred)):   ## If you just want so see the failing examples\n",
    "                    datacv = datacv.cpu()\n",
    "                    grid = utils.make_grid(datacv)\n",
    "                    grid = grid.numpy().transpose((1,2,0))\n",
    "                    #plt.imshow(grid)\n",
    "                    #cv_mat = data.cpu().data.squeeze().numpy()\n",
    "                    #cv_mat = cv2.resize(cv_mat, (128, 640))\n",
    "                    #plt.figure(figsize=(320,64))\n",
    "                    cv2.imshow(\"test image\", grid)\n",
    "                    #plt.axis('off')\n",
    "                    #plt.ioff()\n",
    "                    #plt.show()\n",
    "                    print(command.item())\n",
    "                    print(\"Target label is : %d\" % target.cpu().item())\n",
    "                    print(\"Predicted label is : %d\" % (pred.cpu().data.item()))\n",
    "                    cv2.waitKey()\n",
    "                 '''\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= len(TestData.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(TestData.dataset),\n",
    "        100. * correct / len(TestData.dataset)))\n",
    "\n",
    "    \n",
    "def main():\n",
    "    num_train_epochs = 10\n",
    "    for epoch in range(1, num_train_epochs + 1):\n",
    "        train(epoch)\n",
    "    test()\n",
    "    \n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n",
    "#torch.save(model.state_dict(), \"Netz_state2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.],\n",
      "        [3.],\n",
      "        [4.]])\n"
     ]
    }
   ],
   "source": [
    "j = torch.tensor([[8],[3],[4]]).type('torch.FloatTensor')\n",
    "\n",
    "var = [] \n",
    "for I in j:\n",
    "\n",
    "    var.append(I.unsqueeze(0))\n",
    "var_tensor = torch.cat(var)\n",
    "print(var_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This function trains the neural network for one epoch\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(dataloader):\n",
    "        # Move the input and target data on the GPU\n",
    "        sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "        sample['steer'] = sample['steer'].type('torch.FloatTensor')\n",
    "        \n",
    "        data, target = sample['image'].to(device), sample['steer'].to(device)  # .cuda() works too instead of .to(device)\n",
    "        #loss = nn.L1Loss()\n",
    "        # Zero out gradients from previous step\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #print(output.type())\n",
    "        #print(\"target\")\n",
    "        #print(target.type())\n",
    "        #output = output.squeeze()\n",
    "        #loss = F.nll_loss(output, target)\n",
    "        loss = F.smooth_l1_loss(output, target)\n",
    "        #loss = loss(output, target)\n",
    "        loss.backward()\n",
    "        # Adjusting the parameters according to the loss function\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(dataloader.dataset),\n",
    "                100. * batch_idx / len(dataloader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = torch.device(\"cpu\")\n",
    "# Definition of the network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)    # FYI: In the lecture I forgot to add the padding, thats why the feature size calculation was wrong\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv8_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(327680, 50)\n",
    "        self.fc2 = nn.Linear(50, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)),2)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8_drop(self.conv8(x)))\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = x.view(-1, 327680)   # Flatten data for fully connected layer. Input size is 28*28, we have 2 pooling layers so we pool the spatial size down to 7*7. With 20 feature maps as the output of the previous conv we have in total 7x7x20 = 980 features.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "        '''\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x),2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv4(x),2))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv8_drop(self.conv8(x)), 2))\n",
    "        x = x.view(-1, 327680)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "        '''\n",
    "# We create the network, shift it on the GPU and define a optimizer on its parameters\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This function trains the neural network for one epoch\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(dataloader):\n",
    "        # Move the input and target data on the GPU\n",
    "        sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "        sample['steer'] = sample['steer'].type('torch.FloatTensor')\n",
    "        \n",
    "        data, target = sample['image'].to(device), sample['steer'].to(device)  # .cuda() works too instead of .to(device)\n",
    "        #loss = nn.L1Loss()\n",
    "        # Zero out gradients from previous step\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #print(output.type())\n",
    "        #print(\"target\")\n",
    "        #print(target.type())\n",
    "        #output = output.squeeze()\n",
    "        #loss = F.nll_loss(output, target)\n",
    "        loss = F.smooth_l1_loss(output, target)\n",
    "        #loss = loss(output, target)\n",
    "        loss.backward()\n",
    "        # Adjusting the parameters according to the loss function\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(dataloader.dataset),\n",
    "                100. * batch_idx / len(dataloader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for sample in dataloader2:\n",
    "            # Move the input and target data on the GPU\n",
    "            sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "            sample['steer'] = sample['steer'].type('torch.FloatTensor')\n",
    "            #loss = nn.L1Loss()\n",
    "            data, target = sample['image'].to(device), sample['steer'].to(device)  # .cuda() works too instead of .to(device)\n",
    "            output = model(data)\n",
    "            #output = output.squeeze()\n",
    "            #print(output)\n",
    "            #test_loss += F.nll_loss(output, target).item()\n",
    "            test_loss += F.smooth_l1_loss(output, target, size_average=False).item() # sum up batch loss\n",
    "            #test_loss += loss(output, target).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            #print(pred)\n",
    "            print(target)\n",
    "            #pred = output # get the index of the max log-probability\n",
    "            '''\n",
    "            if not pred.eq(target.view_as(pred)):   ## If you just want so see the failing examples\n",
    "                cv_mat = data.cuda().data.squeeze().numpy()\n",
    "                cv_mat = cv2.resize(cv_mat, (400, 400))\n",
    "                cv2.imshow(\"test image\", cv_mat)\n",
    "                print(\"Target label is : %d\" % target.cuda().item())\n",
    "                print(\"Predicted label is : %d\" % (pred.cuda().data.item()))\n",
    "                cv2.waitKey()\n",
    "            '''\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= len(dataloader2.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(dataloader2.dataset),\n",
    "        100. * correct / len(dataloader2.dataset)))\n",
    "\n",
    "num_train_epochs = 2\n",
    "for epoch in range(1, num_train_epochs + 1):\n",
    "    train(epoch)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a fucntion that iter on dictionary to anlyse the dataset\n",
    "ChosenDataset = 'DataDictAllOk1.txt'\n",
    "with open(ChosenDataset, 'rb') as f:\n",
    "    DataDictAllOk1 = serializer.load(f)\n",
    "ChosenDataset = 'DataDictHot.txt'\n",
    "with open(ChosenDataset, 'rb') as f:\n",
    "    DataDictHot = serializer.load(f)\n",
    "\n",
    "ctr = 0\n",
    "for i in range(0, len(DataDictAllOk1['direction'])):\n",
    "    if DataDictAllOk1['direction'][i] == 'left':\n",
    "        DataDictAllOk1['direction'][i] = 0\n",
    "    if DataDictAllOk1['direction'][i] == 'forward':\n",
    "        DataDictAllOk1['direction'][i] = 1\n",
    "    if DataDictAllOk1['direction'][i] == 'right':\n",
    "        DataDictAllOk1['direction'][i] = 2\n",
    "    ctr+=1\n",
    "\n",
    "print(ctr)\n",
    "with open('DataDictAllOk1.txt', 'wb') as f:\n",
    "    serializer.dump(DataDictHot, f)           \n",
    "\n",
    "#right on command right = 752 sharf 340\n",
    "#left on command left= 600\n",
    "#right on command left = 295, sharf 101\n",
    "# left on command right = 101\n",
    "#268 -0.8\n",
    "#1845 left, 1737 right, \n",
    "# DictAllOk1 left -0.8 522, -0.2 1121, \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = 'image'\n",
    "y = 3\n",
    "for j in range(0, len(DataDictHot[x])):\n",
    "    gut = 'Bilder/'+ DataDictHot[x][j]\n",
    "    if not os.path.exists(gut):\n",
    "        print(bad)\n",
    "print(len(DataDictHot[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChosenDataset = 'DataDictAllOk1.txt'\n",
    "with open(ChosenDataset, 'rb') as f:\n",
    "    DataDictAllOk1 = serializer.load(f)\n",
    "ChosenDataset = 'DataDictHot.txt'\n",
    "with open(ChosenDataset, 'rb') as f:\n",
    "    DataDictHot = serializer.load(f)\n",
    "\n",
    "x = 'right'\n",
    "y = 3\n",
    "for j in range(0, len(dataset0[x])):\n",
    "    gut = 'Bilder/'+ dataset0[x][j][0]\n",
    "    if os.path.exists(gut):\n",
    "        DataDictHot[\"image\"].append(dataset0[x][j][0])\n",
    "        if dataset0[x][j][1] == -0.8:\n",
    "            DataDictHot[\"steer\"].append(0)\n",
    "        elif dataset0[x][j][1] == -0.2:\n",
    "            DataDictHot[\"steer\"].append(1)\n",
    "        elif dataset0[x][j][1] == 0:\n",
    "            DataDictHot[\"steer\"].append(2)\n",
    "        elif dataset0[x][j][1] == 0.2:\n",
    "            DataDictHot[\"steer\"].append(3)\n",
    "        elif dataset0[x][j][1] == 0.8:\n",
    "            DataDictHot[\"steer\"].append(4)\n",
    "        DataDictHot[\"throttle\"].append(dataset0[x][j][2])\n",
    "        DataDictHot[\"direction\"].append(dataset0[x][j][3])\n",
    "        DataDictHot[\"command\"].append(y)\n",
    "        #print(dataset0['right'][j])\n",
    "        ctr2 +=1\n",
    "     \n",
    "\n",
    "print(len(DataDictHot['command']))\n",
    "print(len(DataDictAllOk1['command']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

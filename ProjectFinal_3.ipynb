{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a69368215d88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch.nn.functional as F\n",
    "torch.set_printoptions(linewidth=120)\n",
    "\n",
    "import pickle as serializer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this function seperates the different commands in 4 different dictionaries\n",
    "# DataDict0 is for command0 'continue'\n",
    "# DataDict1 is for command1 'left'\n",
    "# DataDict2 is for command2 'forward'\n",
    "# DataDict3 is for command3 'right'\n",
    "\n",
    "# Coding of values\n",
    "# command: 0 --> conintue, 1 -->left, 2 --> forward, 3 --> right. \n",
    "# direction: 0 --> left, 1 --> forward, 2 --> right.\n",
    "#Steer: [0 --> -0.8] ,[1 --> -0.2],[2 --> 0],[3 --> 0.2],[4 --> 0.8].\n",
    "\n",
    "\n",
    "with open('dataset.txt', 'rb') as f:\n",
    "    dataset = serializer.load(f)\n",
    "    \n",
    "DataDictAll = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "DataDict0 = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "DataDict1 = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "DataDict2 = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "DataDict3 = {\"image\":[],\"steer\":[],\"throttle\":[],\"direction\":[],\"command\":[]}\n",
    "[c0, c1, c2,c3, c4] = [0,0,0,0,0]\n",
    "keys = dataset.keys()\n",
    "for key in keys:\n",
    "    for label in dataset[key]:\n",
    "        #DataDict[\"image\"].append(label[0])\n",
    "        if label[3] == 'left':\n",
    "            label[3] = 0\n",
    "        if label[3] == 'right':\n",
    "            label[3] = 2\n",
    "        if label[3] == 'forward':\n",
    "            label[3] = 1\n",
    "\n",
    "        if label[1] == -0.8:\n",
    "            label[1] = 0\n",
    "            c0+=1\n",
    "        if label[1] == -0.2:\n",
    "            label[1] = 1\n",
    "            c1+=1\n",
    "        if label[1] == 0:\n",
    "            label[1] = 2\n",
    "            c2+=1\n",
    "        if label[1] == 0.2:\n",
    "            label[1] = 3\n",
    "            c3+=1\n",
    "        if label[1] == 0.8:\n",
    "            label[1] = 4\n",
    "            #if label[]c4 +=1\n",
    "        if key == 'left':\n",
    "            key = 1\n",
    "            label.append(key)\n",
    "            DataDict1[\"image\"].append(label[0])\n",
    "            DataDict1[\"steer\"].append(label[1])\n",
    "            DataDict1[\"throttle\"].append(label[2])\n",
    "            DataDict1[\"direction\"].append(label[3])\n",
    "            DataDict1[\"command\"].append(label[4])\n",
    "            \n",
    "        if key == 'right':\n",
    "            key = 3\n",
    "            \n",
    "            label.append(key)\n",
    "            DataDict3[\"image\"].append(label[0])\n",
    "            DataDict3[\"steer\"].append(label[1])\n",
    "            DataDict3[\"throttle\"].append(label[2])\n",
    "            DataDict3[\"direction\"].append(label[3])\n",
    "            DataDict3[\"command\"].append(label[4])\n",
    "            \n",
    "        if key == 'forward':\n",
    "            key = 2\n",
    "            \n",
    "            label.append(key)\n",
    "            DataDict2[\"image\"].append(label[0])\n",
    "            DataDict2[\"steer\"].append(label[1])\n",
    "            DataDict2[\"throttle\"].append(label[2])\n",
    "            DataDict2[\"direction\"].append(label[3])\n",
    "            DataDict2[\"command\"].append(label[4])\n",
    "            \n",
    "        if key == 'continue':\n",
    "            key = 0\n",
    "            \n",
    "            label.append(key)\n",
    "            DataDict0[\"image\"].append(label[0])\n",
    "            DataDict0[\"steer\"].append(label[1])\n",
    "            DataDict0[\"throttle\"].append(label[2])\n",
    "            DataDict0[\"direction\"].append(label[3])\n",
    "            DataDict0[\"command\"].append(label[4])\n",
    "    \n",
    "        gut = 'Bilder/'+ label[0]\n",
    "        if os.path.exists(gut):\n",
    "            if key == 1:\n",
    "                label.append(key)\n",
    "                DataDict1[\"image\"].append(label[0])\n",
    "                DataDict1[\"steer\"].append(label[1])\n",
    "                DataDict1[\"throttle\"].append(label[2])\n",
    "                DataDict1[\"direction\"].append(label[3])\n",
    "                DataDict1[\"command\"].append(label[4])\n",
    "            if key == 3:\n",
    "                label.append(key)\n",
    "                DataDict3[\"image\"].append(label[0])\n",
    "                DataDict3[\"steer\"].append(label[1])\n",
    "                DataDict3[\"throttle\"].append(label[2])\n",
    "                DataDict3[\"direction\"].append(label[3])\n",
    "                DataDict3[\"command\"].append(label[4])\n",
    "            if key == 2:\n",
    "                label.append(key)\n",
    "                DataDict2[\"image\"].append(label[0])\n",
    "                DataDict2[\"steer\"].append(label[1])\n",
    "                DataDict2[\"throttle\"].append(label[2])\n",
    "                DataDict2[\"direction\"].append(label[3])\n",
    "                DataDict2[\"command\"].append(label[4])\n",
    "            if key == 0:\n",
    "                label.append(key)\n",
    "                DataDict0[\"image\"].append(label[0])\n",
    "                DataDict0[\"steer\"].append(label[1])\n",
    "                DataDict0[\"throttle\"].append(label[2])\n",
    "                DataDict0[\"direction\"].append(label[3])\n",
    "                DataDict0[\"command\"].append(label[4])\n",
    "            label.append(key)\n",
    "            DataDictAll[\"image\"].append(label[0])\n",
    "            DataDictAll[\"steer\"].append(label[1])\n",
    "            DataDictAll[\"throttle\"].append(label[2])\n",
    "            DataDictAll[\"direction\"].append(label[3])\n",
    "            DataDictAll[\"command\"].append(label[4])\n",
    "            \n",
    "print([c0,c1,c2,c3,c4])\n",
    "print(DataDict0['steer'])\n",
    "\n",
    "with open('DataDictAll.txt', 'wb') as f:\n",
    "    serializer.dump(DataDictAll, f)\n",
    "\n",
    "with open('DataDict0.txt', 'wb') as f:\n",
    "    serializer.dump(DataDict0, f)\n",
    "\n",
    "with open('DataDict1.txt', 'wb') as f:\n",
    "    serializer.dump(DataDict1, f)\n",
    "\n",
    "with open('DataDict2.txt', 'wb') as f:\n",
    "    serializer.dump(DataDict2, f)\n",
    "\n",
    "with open('DataDict3.txt', 'wb') as f:\n",
    "    serializer.dump(DataDict3, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chose the DataSet you want to train the network on\n",
    "ChosenDataset = 'DataDictHot.txt'\n",
    "\n",
    "with open(ChosenDataset, 'rb') as f:\n",
    "    dataset = serializer.load(f)\n",
    "\n",
    "class AISProject(Dataset):\n",
    "    \"\"\" AIS Project dataset.\"\"\"\n",
    "    def __init__(self, dictionary, root_dir, transform = None):\n",
    "\n",
    "        self.dictionary = pd.DataFrame.from_dict(dictionary)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        print(len(dictionary))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dictionary)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,self.dictionary.iloc[idx,0])\n",
    "        image = io.imread(img_name)\n",
    "        #steer = torch.tensor(self.dictionary.iloc[idx,1],dtype=torch.float32, requires_grad=True)\n",
    "        steer = torch.tensor(self.dictionary.iloc[idx,1],dtype=torch.long)\n",
    "        speed = torch.tensor(self.dictionary.iloc[idx,2],dtype = torch.float32)\n",
    "        direction = torch.tensor(self.dictionary.iloc[idx,3],dtype = torch.long)\n",
    "        command = torch.tensor(self.dictionary.iloc[idx,4],dtype = torch.uint8)\n",
    "        sample = {'image':image, 'steer': steer, 'speed': speed,'direction':direction, 'command':command }\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, steer, speed, direction, command = sample['image'], sample['steer'], sample['speed'], sample['direction'], sample['command']\n",
    "        image = image.transpose((2,0,1))\n",
    "        return {'image': torch.from_numpy(image), \n",
    "                'steer': torch.tensor(steer),\n",
    "               'speed': torch.tensor(speed),\n",
    "               'direction':torch.tensor(direction),\n",
    "               'command':torch.tensor(command)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    \"\"\"Class to crop our data. (Modified RandomCrop, so that the crop isn't random anymore)\"\"\"\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        #new_h, new_w = output_size\n",
    "        new_h = 64\n",
    "        image = image[new_h:h, 0:w]\n",
    "        #show_image to test whether the pictures are cropped as we wish\n",
    "        #show_image(image)\n",
    "        sample['image'] = image\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nplt.figure()\\nshow_image(io.imread(os.path.join('Bilder/',img_name)))\\nplt.show()\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_image(image):\n",
    "    plt.imshow(image)\n",
    "\n",
    "'''\n",
    "plt.figure()\n",
    "show_image(io.imread(os.path.join('Bilder/',img_name)))\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(transformed_dataset)):\\n    sample = transformed_dataset[i]\\n    \\n    print(i, sample)\\n    if i == 1:\\n        break\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "transformed_dataset = AISProject(dictionary = dataset, root_dir='Bilder/', \n",
    "                                transform = transforms.Compose([ToTensor(), normalize]))\n",
    "transformed_dataset2 = AISProject(dictionary = dataset, root_dir='Bilder/', \n",
    "                                transform = transforms.Compose([ToTensor(), normalize]))\n",
    "'''\n",
    "for i in range(len(transformed_dataset)):\n",
    "    sample = transformed_dataset[i]\n",
    "    \n",
    "    print(i, sample)\n",
    "    if i == 1:\n",
    "        break\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef show_labels_batch(sample_batched):\\n    \"\"\"Show image with labels for a batch of samples.\"\"\"\\n    images_batch, labels_batch =         sample_batched[\\'image\\'], sample_batched[\\'steer\\']\\n    batch_size = len(images_batch)\\n    im_size = images_batch.size(2)\\n    \\n    grid = utils.make_grid(images_batch)\\n    plt.imshow(grid.numpy().transpose((1,2,0)))\\n\\n\\n\\nfor i_batch, sample_batched in enumerate(TrainData):\\n    print(i_batch, sample_batched[\\'image\\'].size(), \\n         sample_batched[\\'steer\\'].size())\\n\\n    if i_batch == 1:\\n        plt.figure(figsize=(40,40))\\n        show_labels_batch(sample_batched)\\n        plt.axis(\\'off\\')\\n        plt.ioff()\\n        plt.show()\\n        break\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData = DataLoader(transformed_dataset, batch_size=32, \n",
    "                        shuffle=True, pin_memory=False,num_workers = 0)\n",
    "TestData = DataLoader(transformed_dataset2, batch_size=1, \n",
    "                        shuffle=True, pin_memory=False)\n",
    "'''\n",
    "for batch_idx, dataset in enumerate(TrainData):\n",
    "    print(batch_idx)\n",
    "    print(dataset['image'].size())\n",
    "    print(dataset['command'].size())\n",
    "    print(dataset['direction'])\n",
    "    if batch_idx == 3:\n",
    "        break\n",
    "'''\n",
    "'''\n",
    "def show_labels_batch(sample_batched):\n",
    "    \"\"\"Show image with labels for a batch of samples.\"\"\"\n",
    "    images_batch, labels_batch = \\\n",
    "        sample_batched['image'], sample_batched['steer']\n",
    "    batch_size = len(images_batch)\n",
    "    im_size = images_batch.size(2)\n",
    "    \n",
    "    grid = utils.make_grid(images_batch)\n",
    "    plt.imshow(grid.numpy().transpose((1,2,0)))\n",
    "\n",
    "\n",
    "\n",
    "for i_batch, sample_batched in enumerate(TrainData):\n",
    "    print(i_batch, sample_batched['image'].size(), \n",
    "         sample_batched['steer'].size())\n",
    "\n",
    "    if i_batch == 1:\n",
    "        plt.figure(figsize=(40,40))\n",
    "        show_labels_batch(sample_batched)\n",
    "        plt.axis('off')\n",
    "        plt.ioff()\n",
    "        plt.show()\n",
    "        break\n",
    "'''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Netz2.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-9ad115b214d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;31m#model1 = Net().to(device)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;31m#torch.save(model1, \"Netz2.pt\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Netz2.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;31m#optimizer = optim.Adam(model.parameters(), lr=0.001)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Programme\\Anaconda\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module)\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Netz2.pt'"
     ]
    }
   ],
   "source": [
    "''' Network with branches '''\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "# Definition of the network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)    # FYI: In the lecture I forgot to add the padding, thats why the feature size calculation was wrong\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv8_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(81920, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        #here we start the branching\n",
    "        # Brach 0\n",
    "        self.fc1B0 = nn.Linear(512, 256)\n",
    "        self.fc2B0 = nn.Linear(256, 256)\n",
    "        self.fc3B0 = nn.Linear(256, 1) # the output is direction\n",
    "        \n",
    "        #ToDo: implement other branches\n",
    "        \n",
    "        # Brach 1\n",
    "        self.fc1B1 = nn.Linear(512, 256)\n",
    "        self.fc2B1 = nn.Linear(256, 256)\n",
    "        self.fc3B1 = nn.Linear(256, 1) # the output is direction\n",
    "        # Brach 2\n",
    "        self.fc1B2 = nn.Linear(512, 256)\n",
    "        self.fc2B2 = nn.Linear(256, 256)\n",
    "        self.fc3B2 = nn.Linear(256, 1) # the output is direction\n",
    "        # Brach 3\n",
    "        self.fc1B3 = nn.Linear(512, 256)\n",
    "        self.fc2B3 = nn.Linear(256, 256)\n",
    "        self.fc3B3 = nn.Linear(256, 1) # the output is directiontput is direction\n",
    "        \n",
    "\n",
    "    def forward(self, x, command):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)),2)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8_drop(self.conv8(x)))\n",
    "        x = F.max_pool2d(x,4)\n",
    "        x = x.view(-1, 81920)   # Flatten data for fully connected layer. Input size is 28*28, we have 2 pooling layers so we pool the spatial size down to 7*7. With 20 feature maps as the output of the previous conv we have in total 7x7x20 = 980 features.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #x = F.dropout(x, training=self.training)\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        # choosing the branch\n",
    "        out = []\n",
    "        y = None\n",
    "        for Idx in range(0,1):\n",
    "            if command[Idx].item() == 0:\n",
    "                x0 = F.relu(self.fc1B0(x))\n",
    "                x0 = F.relu(self.fc2B0(x0))\n",
    "                x0 = F.dropout(x0, training=self.training)\n",
    "                x0 = self.fc3B0(x0)\n",
    "                #print(\"0\")\n",
    "                o0 = F.log_softmax(x0, dim=1)\n",
    "                return o0\n",
    "            #out.append(o0.unsqueeze(0))\n",
    "            elif command[Idx].item() == 1:\n",
    "                x1 = F.relu(self.fc1B1(x))\n",
    "                x1 = F.relu(self.fc2B1(x1))\n",
    "                x1 = F.dropout(x1, training=self.training)\n",
    "                x1 = self.fc3B1(x1)\n",
    "                #print(\"1\")\n",
    "                o1 = F.log_softmax(x1, dim=1)\n",
    "                return o1\n",
    "                #out.append(o1.unsqueeze(0))\n",
    "            elif command[Idx].item() == 2:\n",
    "                x2 = F.relu(self.fc1B2(x))\n",
    "                x2 = F.relu(self.fc2B2(x2))\n",
    "                x2 = F.dropout(x2, training=self.training)\n",
    "                x2 = self.fc3B2(x2)\n",
    "                #print(\"2\")\n",
    "                o2 = F.log_softmax(x2, dim=1)\n",
    "                return o2\n",
    "                #out.append(o2.unsqueeze(0))\n",
    "            elif command[Idx].item() == 3:\n",
    "                x3 = F.relu(self.fc1B3(x))\n",
    "                x3 = F.relu(self.fc2B3(x3))\n",
    "                x3 = F.dropout(x3, training=self.training)\n",
    "                x3 = self.fc3B3(x3)\n",
    "                #print(\"3\")\n",
    "                o3 = F.log_softmax(x3, dim=1)\n",
    "                return o3\n",
    "                #out.append(o3.unsqueeze(0))\n",
    "        #return out\n",
    "        \n",
    "        '''\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x),2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv4(x),2))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv8_drop(self.conv8(x)), 2))\n",
    "        x = x.view(-1, 81920)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "        '''\n",
    "\n",
    "# We create the network, shift it on the GPU and define a optimizer on its parameters\n",
    "#model1 = Net().to(device)\n",
    "#torch.save(model1, \"Netz2.pt\")\n",
    "model = torch.load(\"Netz2.pt\")\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function trains the neural network for one epoch\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(TrainData):\n",
    "        #print(batch_idx)\n",
    "        # Move the input and target data on the GPU\n",
    "        sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "\n",
    "        data, target = sample['image'].to(device), sample['steer'].to(device)  # .cuda() works too instead of .to(device)\n",
    "        command = sample['command']\n",
    "        if True:\n",
    "            out = []\n",
    "            # Zero out gradients from previous step\n",
    "            optimizer.zero_grad()\n",
    "            for i in range(0,len(command)):\n",
    "                output = model(data[i].unsqueeze(0), command[i])\n",
    "                out.append(output)\n",
    "            output = torch.cat(out)\n",
    "            #output = model(data, command)\n",
    "            #print(output.size())\n",
    "            #print(target.size())\n",
    "            #output = model(i, j)\n",
    "            #for i in output:\n",
    "                #print(output)\n",
    "                #output = torch.cat(output)\n",
    "            #print(output.size())\n",
    "            #print(output.shape())\n",
    "            \n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            # Adjusting the parameters according to the loss function\n",
    "            optimizer.step()\n",
    "            if batch_idx % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(TrainData.dataset),\n",
    "                    100. * batch_idx / len(TrainData), loss.item()))\n",
    "    torch.save(model, \"Netz2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-fc1dc73cdb14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;31m#torch.save(model.state_dict(), \"Netz_state2.pt\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-fc1dc73cdb14>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mnum_train_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_train_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m     \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-5d8b72702554>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# This function trains the neural network for one epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrainData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;31m#print(batch_idx)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "def test():\n",
    "    #if os.path.isfile(\"Netz.pt\"):\n",
    "        #model = torch.load(\"Netz.pt\")\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for sample in TestData:\n",
    "            datacv = sample['image']\n",
    "            # Move the input and target data on the GPU\n",
    "            sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "            \n",
    "            #sample['direction'] = sample['direction'].type('torch.FloatTensor')\n",
    "            data, target = sample['image'].to(device), sample['steer'].to(device)  # .cuda() works too instead of .to(device)\n",
    "            command = sample['command']\n",
    "            if True:\n",
    "                output = model(data, command)\n",
    "                test_loss += F.nll_loss(output, target).item()\n",
    "                pred = output.max(1, keepdim=True)[1]\n",
    "                #pred = output # get the index of the max log-probability\n",
    "                '''\n",
    "                if not pred.eq(target.view_as(pred)):   ## If you just want so see the failing examples\n",
    "                    datacv = datacv.cpu()\n",
    "                    grid = utils.make_grid(datacv)\n",
    "                    grid = grid.numpy().transpose((1,2,0))\n",
    "                    #plt.imshow(grid)\n",
    "                    #cv_mat = data.cpu().data.squeeze().numpy()\n",
    "                    #cv_mat = cv2.resize(cv_mat, (128, 640))\n",
    "                    #plt.figure(figsize=(320,64))\n",
    "                    cv2.imshow(\"test image\", grid)\n",
    "                    #plt.axis('off')\n",
    "                    #plt.ioff()\n",
    "                    #plt.show()\n",
    "                    print(command.item())\n",
    "                    print(\"Target label is : %d\" % target.cpu().item())\n",
    "                    print(\"Predicted label is : %d\" % (pred.cpu().data.item()))\n",
    "                    cv2.waitKey()\n",
    "                 '''\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= len(TestData.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(TestData.dataset),\n",
    "        100. * correct / len(TestData.dataset)))\n",
    "\n",
    "    \n",
    "def main():\n",
    "    num_train_epochs = 10\n",
    "    for epoch in range(1, num_train_epochs + 1):\n",
    "        train(epoch)\n",
    "    test()\n",
    "    \n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()\n",
    "#torch.save(model.state_dict(), \"Netz_state2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.],\n",
      "        [3.],\n",
      "        [4.]])\n"
     ]
    }
   ],
   "source": [
    "j = torch.tensor([[8],[3],[4]]).type('torch.FloatTensor')\n",
    "\n",
    "var = [] \n",
    "for I in j:\n",
    "\n",
    "    var.append(I.unsqueeze(0))\n",
    "var_tensor = torch.cat(var)\n",
    "print(var_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This function trains the neural network for one epoch\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(dataloader):\n",
    "        # Move the input and target data on the GPU\n",
    "        sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "        sample['steer'] = sample['steer'].type('torch.FloatTensor')\n",
    "        \n",
    "        data, target = sample['image'].to(device), sample['steer'].to(device)  # .cuda() works too instead of .to(device)\n",
    "        #loss = nn.L1Loss()\n",
    "        # Zero out gradients from previous step\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #print(output.type())\n",
    "        #print(\"target\")\n",
    "        #print(target.type())\n",
    "        #output = output.squeeze()\n",
    "        #loss = F.nll_loss(output, target)\n",
    "        loss = F.smooth_l1_loss(output, target)\n",
    "        #loss = loss(output, target)\n",
    "        loss.backward()\n",
    "        # Adjusting the parameters according to the loss function\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(dataloader.dataset),\n",
    "                100. * batch_idx / len(dataloader), loss.item()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = torch.device(\"cpu\")\n",
    "# Definition of the network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, padding=2)    # FYI: In the lecture I forgot to add the padding, thats why the feature size calculation was wrong\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv8_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(327680, 50)\n",
    "        self.fc2 = nn.Linear(50, 5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),2)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)),2)\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(self.conv8_drop(self.conv8(x)))\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = x.view(-1, 327680)   # Flatten data for fully connected layer. Input size is 28*28, we have 2 pooling layers so we pool the spatial size down to 7*7. With 20 feature maps as the output of the previous conv we have in total 7x7x20 = 980 features.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "        '''\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x),2))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv4(x),2))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.relu(self.conv6(x))\n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.relu(F.max_pool2d(self.conv8_drop(self.conv8(x)), 2))\n",
    "        x = x.view(-1, 327680)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "        '''\n",
    "# We create the network, shift it on the GPU and define a optimizer on its parameters\n",
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This function trains the neural network for one epoch\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, sample in enumerate(dataloader):\n",
    "        # Move the input and target data on the GPU\n",
    "        sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "        sample['steer'] = sample['steer'].type('torch.FloatTensor')\n",
    "        \n",
    "        data, target = sample['image'].to(device), sample['steer'].to(device)  # .cuda() works too instead of .to(device)\n",
    "        #loss = nn.L1Loss()\n",
    "        # Zero out gradients from previous step\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #print(output.type())\n",
    "        #print(\"target\")\n",
    "        #print(target.type())\n",
    "        #output = output.squeeze()\n",
    "        #loss = F.nll_loss(output, target)\n",
    "        loss = F.smooth_l1_loss(output, target)\n",
    "        #loss = loss(output, target)\n",
    "        loss.backward()\n",
    "        # Adjusting the parameters according to the loss function\n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(dataloader.dataset),\n",
    "                100. * batch_idx / len(dataloader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for sample in dataloader2:\n",
    "            # Move the input and target data on the GPU\n",
    "            sample['image'] = sample['image'].type('torch.FloatTensor')\n",
    "            sample['steer'] = sample['steer'].type('torch.FloatTensor')\n",
    "            #loss = nn.L1Loss()\n",
    "            data, target = sample['image'].to(device), sample['steer'].to(device)  # .cuda() works too instead of .to(device)\n",
    "            output = model(data)\n",
    "            #output = output.squeeze()\n",
    "            #print(output)\n",
    "            #test_loss += F.nll_loss(output, target).item()\n",
    "            test_loss += F.smooth_l1_loss(output, target, size_average=False).item() # sum up batch loss\n",
    "            #test_loss += loss(output, target).item()\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            #print(pred)\n",
    "            print(target)\n",
    "            #pred = output # get the index of the max log-probability\n",
    "            '''\n",
    "            if not pred.eq(target.view_as(pred)):   ## If you just want so see the failing examples\n",
    "                cv_mat = data.cuda().data.squeeze().numpy()\n",
    "                cv_mat = cv2.resize(cv_mat, (400, 400))\n",
    "                cv2.imshow(\"test image\", cv_mat)\n",
    "                print(\"Target label is : %d\" % target.cuda().item())\n",
    "                print(\"Predicted label is : %d\" % (pred.cuda().data.item()))\n",
    "                cv2.waitKey()\n",
    "            '''\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "\n",
    "    test_loss /= len(dataloader2.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(dataloader2.dataset),\n",
    "        100. * correct / len(dataloader2.dataset)))\n",
    "\n",
    "num_train_epochs = 2\n",
    "for epoch in range(1, num_train_epochs + 1):\n",
    "    train(epoch)\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a fucntion that iter on dictionary to anlyse the dataset\n",
    "ChosenDataset = 'DataDictAllOk1.txt'\n",
    "with open(ChosenDataset, 'rb') as f:\n",
    "    DataDictAllOk1 = serializer.load(f)\n",
    "ChosenDataset = 'DataDictHot.txt'\n",
    "with open(ChosenDataset, 'rb') as f:\n",
    "    DataDictHot = serializer.load(f)\n",
    "\n",
    "ctr = 0\n",
    "for i in range(0, len(DataDictAllOk1['direction'])):\n",
    "    if DataDictAllOk1['direction'][i] == 'left':\n",
    "        DataDictAllOk1['direction'][i] = 0\n",
    "    if DataDictAllOk1['direction'][i] == 'forward':\n",
    "        DataDictAllOk1['direction'][i] = 1\n",
    "    if DataDictAllOk1['direction'][i] == 'right':\n",
    "        DataDictAllOk1['direction'][i] = 2\n",
    "    ctr+=1\n",
    "\n",
    "print(ctr)\n",
    "with open('DataDictAllOk1.txt', 'wb') as f:\n",
    "    serializer.dump(DataDictHot, f)           \n",
    "\n",
    "#right on command right = 752 sharf 340\n",
    "#left on command left= 600\n",
    "#right on command left = 295, sharf 101\n",
    "# left on command right = 101\n",
    "#268 -0.8\n",
    "#1845 left, 1737 right, \n",
    "# DictAllOk1 left -0.8 522, -0.2 1121, \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = 'image'\n",
    "y = 3\n",
    "for j in range(0, len(DataDictHot[x])):\n",
    "    gut = 'Bilder/'+ DataDictHot[x][j]\n",
    "    if not os.path.exists(gut):\n",
    "        print(bad)\n",
    "print(len(DataDictHot[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChosenDataset = 'DataDictAllOk1.txt'\n",
    "with open(ChosenDataset, 'rb') as f:\n",
    "    DataDictAllOk1 = serializer.load(f)\n",
    "ChosenDataset = 'DataDictHot.txt'\n",
    "with open(ChosenDataset, 'rb') as f:\n",
    "    DataDictHot = serializer.load(f)\n",
    "\n",
    "x = 'right'\n",
    "y = 3\n",
    "for j in range(0, len(dataset0[x])):\n",
    "    gut = 'Bilder/'+ dataset0[x][j][0]\n",
    "    if os.path.exists(gut):\n",
    "        DataDictHot[\"image\"].append(dataset0[x][j][0])\n",
    "        if dataset0[x][j][1] == -0.8:\n",
    "            DataDictHot[\"steer\"].append(0)\n",
    "        elif dataset0[x][j][1] == -0.2:\n",
    "            DataDictHot[\"steer\"].append(1)\n",
    "        elif dataset0[x][j][1] == 0:\n",
    "            DataDictHot[\"steer\"].append(2)\n",
    "        elif dataset0[x][j][1] == 0.2:\n",
    "            DataDictHot[\"steer\"].append(3)\n",
    "        elif dataset0[x][j][1] == 0.8:\n",
    "            DataDictHot[\"steer\"].append(4)\n",
    "        DataDictHot[\"throttle\"].append(dataset0[x][j][2])\n",
    "        DataDictHot[\"direction\"].append(dataset0[x][j][3])\n",
    "        DataDictHot[\"command\"].append(y)\n",
    "        #print(dataset0['right'][j])\n",
    "        ctr2 +=1\n",
    "     \n",
    "\n",
    "print(len(DataDictHot['command']))\n",
    "print(len(DataDictAllOk1['command']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
